{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RandomizedLasso\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names, start = 0, stop = 40000)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_delta_phi(x):\n",
    "    if x > math.pi:\n",
    "        delta_phi = x - 2*math.pi\n",
    "    elif x < -math.pi:\n",
    "        delta_phi = x + 2*math.pi\n",
    "    else:\n",
    "        delta_phi = x\n",
    "    return delta_phi\n",
    "\n",
    "def calculate_delta_R(phi_1, phi_2, eta_1, eta_2):\n",
    "    x = phi_1 - phi_2\n",
    "    delta_phi = process_delta_phi(x)\n",
    "    delta_eta = eta_1 - eta_2\n",
    "    return math.sqrt(delta_phi**2 + delta_eta**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(df):\n",
    "    \n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number','event_weight','delta_phi','delta_eta','delta_R','invmass','lepton_delta_R','lepton_delta_eta','H']\n",
    "    \n",
    "    for t in range(1,3):\n",
    "        for i in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "    \n",
    "    columns.append('result')\n",
    "    \n",
    "    overall = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6 and df['jet_CSV'][i][2] > 0.8:\n",
    "            checked = 0\n",
    "            for m in range(df['jet_number'][i]):\n",
    "                if df['jet_pT'][i][m] > 20 and np.abs(dftree_bg['jet_eta'][i][m]) < 2.4:\n",
    "                    checked += 1\n",
    "            if checked < 6:\n",
    "                continue\n",
    "                \n",
    "            count = 0\n",
    "            \n",
    "            #append all the invariant columns\n",
    "            invariants = []\n",
    "            \n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number']:\n",
    "                invariants.append(df[t][i])\n",
    "                \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            invariants.append(product)\n",
    "            \n",
    "            #Loop over possible combinations\n",
    "            for t in [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3)]:\n",
    "                \n",
    "                #initialize variant data column\n",
    "                variants = []\n",
    "                \n",
    "                #set the jet pair\n",
    "                jet_pair = (t[0],t[1])\n",
    "                \n",
    "                #Delta_phi, delta_eta and delta_R\n",
    "                x = df['jet_phi'][i][jet_pair[0]] - df['jet_phi'][i][jet_pair[1]]\n",
    "                delta_phi = process_delta_phi(x)\n",
    "                delta_eta = df['jet_eta'][i][jet_pair[0]] - df['jet_eta'][i][jet_pair[1]]\n",
    "                delta_R = math.sqrt(delta_phi**2 + delta_eta**2)\n",
    "\n",
    "                #invmass\n",
    "                pt1, pt2 = math.fabs(df['jet_pT'][i][jet_pair[0]]), math.fabs(df['jet_pT'][i][jet_pair[1]])\n",
    "                pX1, pX2 = pt1 * math.cos(df['jet_phi'][i][jet_pair[0]]), pt2 * math.cos(df['jet_phi'][i][jet_pair[1]])\n",
    "                pY1, pY2 = pt1 * math.sin(df['jet_phi'][i][jet_pair[0]]), pt2 * math.sin(df['jet_phi'][i][jet_pair[1]])\n",
    "                pZ1, pZ2 = pt1 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[0]]))), pt2 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[1]])))\n",
    "                invmass = math.sqrt((df['jet_E'][i][jet_pair[0]] + df['jet_E'][i][jet_pair[1]])**2 - (pX1 + pX2)**2 - (pY1 + pY2)**2 - (pZ1 + pZ2)**2)\n",
    "\n",
    "                #H\n",
    "                H = df['jet_pT'][i][jet_pair[0]] + df['jet_pT'][i][jet_pair[1]] + df['lepton_pT'][i]\n",
    "\n",
    "                #delta_lepton_R\n",
    "                y = df['jet_phi'][i][1] - df['lepton_phi'][i]\n",
    "                delta_phi_lep = process_delta_phi(x)\n",
    "                delta_eta_lep = df['jet_eta'][i][1] - df['lepton_eta'][i]\n",
    "                delta_R_lep = math.sqrt(delta_phi_lep**2 + delta_eta_lep**2)\n",
    "\n",
    "                variants += [delta_phi, delta_eta, delta_R, invmass, delta_R_lep, delta_eta_lep, H]\n",
    "                \n",
    "                for m in [t[0], t[1]]:\n",
    "                    for k in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "                        variants += [df[k][i][m]]\n",
    "\n",
    "                phi_1, phi_2 = dftree_bg['jet_phi'][i][t[0]], dftree_bg['jet_phi'][i][t[1]]\n",
    "                mt_phi_1, mt_phi_2 = dftree_bg['addbjet1_phi'][i], dftree_bg['addbjet2_phi'][i]\n",
    "                eta_1, eta_2 = dftree_bg['jet_eta'][i][t[0]], dftree_bg['jet_eta'][i][t[1]]\n",
    "                mt_eta_1, mt_eta_2 = dftree_bg['addbjet1_eta'][i], dftree_bg['addbjet2_eta'][i]\n",
    "\n",
    "                dR_11 = calculate_delta_R(phi_1, mt_phi_1, eta_1, mt_eta_1)\n",
    "                dR_12 = calculate_delta_R(phi_1, mt_phi_2, eta_1, mt_eta_2)\n",
    "                dR_21 = calculate_delta_R(phi_2, mt_phi_1, eta_2, mt_eta_1)\n",
    "                dR_22 = calculate_delta_R(phi_2, mt_phi_2, eta_2, mt_eta_2)\n",
    "\n",
    "                variants.append(1 if (dR_11 < 0.4 or dR_12 < 0.4) and (dR_21 < 0.4 or dR_22 < 0.4) else 0)\n",
    "                count += 1\n",
    "                \n",
    "                overall.append(invariants + variants)\n",
    "            \n",
    "    print \"Column Length: \", len(overall[0])\n",
    "    print \"Fixed Length: \", len(columns)\n",
    "\n",
    "    train_tree = pd.DataFrame(overall, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Length:  24\n",
      "Fixed Length:  24\n"
     ]
    }
   ],
   "source": [
    "train = generate(dftree_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45455\n",
       "1     6145\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(data):\n",
    "    \n",
    "    pos_events = data[data['result'] == 1]\n",
    "    neg_events = data[data['result'] == 0]\n",
    "    \n",
    "    #Randomize and pick same n number of events\n",
    "    number_pos_events = len(pos_events)  \n",
    "\n",
    "    pos_events = pos_events.reindex(np.random.permutation(pos_events.index))\n",
    "    neg_events = neg_events.reindex(np.random.permutation(neg_events.index))\n",
    "        \n",
    "    undersampled_events = pd.concat([neg_events.head(number_pos_events), pos_events])\n",
    "    X_data_u, scaler = preprocess_data(undersampled_events.drop('result',1))\n",
    "    y_data_u = undersampled_events['result'] \n",
    "\n",
    "    X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(X_data_u, y_data_u, test_size=0.3)\n",
    "    \n",
    "    return X_train_u, X_test_u, y_train_u, y_test_u, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, scaler = under_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(60))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(45))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(15))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.05, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_test_nn = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8603 samples, validate on 3687 samples\n",
      "Epoch 1/70\n",
      " - 1s - loss: 0.6793 - acc: 0.5693 - val_loss: 0.6532 - val_acc: 0.6306\n",
      "Epoch 2/70\n",
      " - 0s - loss: 0.6373 - acc: 0.6464 - val_loss: 0.6099 - val_acc: 0.6786\n",
      "Epoch 3/70\n",
      " - 0s - loss: 0.6130 - acc: 0.6738 - val_loss: 0.5950 - val_acc: 0.6919\n",
      "Epoch 4/70\n",
      " - 0s - loss: 0.6050 - acc: 0.6774 - val_loss: 0.5898 - val_acc: 0.6919\n",
      "Epoch 5/70\n",
      " - 0s - loss: 0.5985 - acc: 0.6873 - val_loss: 0.5828 - val_acc: 0.6984\n",
      "Epoch 6/70\n",
      " - 0s - loss: 0.5921 - acc: 0.6892 - val_loss: 0.5809 - val_acc: 0.6970\n",
      "Epoch 7/70\n",
      " - 0s - loss: 0.5904 - acc: 0.6910 - val_loss: 0.5786 - val_acc: 0.6992\n",
      "Epoch 8/70\n",
      " - 0s - loss: 0.5839 - acc: 0.6927 - val_loss: 0.5750 - val_acc: 0.7025\n",
      "Epoch 9/70\n",
      " - 0s - loss: 0.5838 - acc: 0.6936 - val_loss: 0.5729 - val_acc: 0.7068\n",
      "Epoch 10/70\n",
      " - 0s - loss: 0.5811 - acc: 0.6938 - val_loss: 0.5699 - val_acc: 0.7044\n",
      "Epoch 11/70\n",
      " - 0s - loss: 0.5787 - acc: 0.6979 - val_loss: 0.5679 - val_acc: 0.7065\n",
      "Epoch 12/70\n",
      " - 0s - loss: 0.5772 - acc: 0.7002 - val_loss: 0.5671 - val_acc: 0.7087\n",
      "Epoch 13/70\n",
      " - 0s - loss: 0.5756 - acc: 0.7014 - val_loss: 0.5660 - val_acc: 0.7074\n",
      "Epoch 14/70\n",
      " - 0s - loss: 0.5755 - acc: 0.6989 - val_loss: 0.5660 - val_acc: 0.7095\n",
      "Epoch 15/70\n",
      " - 0s - loss: 0.5747 - acc: 0.7032 - val_loss: 0.5641 - val_acc: 0.7087\n",
      "Epoch 16/70\n",
      " - 0s - loss: 0.5695 - acc: 0.7041 - val_loss: 0.5614 - val_acc: 0.7122\n",
      "Epoch 17/70\n",
      " - 0s - loss: 0.5726 - acc: 0.7039 - val_loss: 0.5622 - val_acc: 0.7130\n",
      "Epoch 18/70\n",
      " - 0s - loss: 0.5680 - acc: 0.7050 - val_loss: 0.5605 - val_acc: 0.7141\n",
      "Epoch 19/70\n",
      " - 0s - loss: 0.5659 - acc: 0.7107 - val_loss: 0.5602 - val_acc: 0.7122\n",
      "Epoch 20/70\n",
      " - 0s - loss: 0.5658 - acc: 0.7071 - val_loss: 0.5595 - val_acc: 0.7179\n",
      "Epoch 21/70\n",
      " - 0s - loss: 0.5626 - acc: 0.7103 - val_loss: 0.5586 - val_acc: 0.7196\n",
      "Epoch 22/70\n",
      " - 0s - loss: 0.5659 - acc: 0.7050 - val_loss: 0.5586 - val_acc: 0.7141\n",
      "Epoch 23/70\n",
      " - 0s - loss: 0.5597 - acc: 0.7113 - val_loss: 0.5585 - val_acc: 0.7122\n",
      "Epoch 24/70\n",
      " - 0s - loss: 0.5573 - acc: 0.7159 - val_loss: 0.5547 - val_acc: 0.7171\n",
      "Epoch 25/70\n",
      " - 0s - loss: 0.5572 - acc: 0.7199 - val_loss: 0.5550 - val_acc: 0.7201\n",
      "Epoch 26/70\n",
      " - 0s - loss: 0.5588 - acc: 0.7138 - val_loss: 0.5543 - val_acc: 0.7234\n",
      "Epoch 27/70\n",
      " - 0s - loss: 0.5599 - acc: 0.7132 - val_loss: 0.5535 - val_acc: 0.7228\n",
      "Epoch 28/70\n",
      " - 0s - loss: 0.5545 - acc: 0.7163 - val_loss: 0.5516 - val_acc: 0.7234\n",
      "Epoch 29/70\n",
      " - 0s - loss: 0.5590 - acc: 0.7185 - val_loss: 0.5539 - val_acc: 0.7182\n",
      "Epoch 30/70\n",
      " - 0s - loss: 0.5550 - acc: 0.7206 - val_loss: 0.5523 - val_acc: 0.7231\n",
      "Epoch 31/70\n",
      " - 0s - loss: 0.5509 - acc: 0.7227 - val_loss: 0.5512 - val_acc: 0.7225\n",
      "Epoch 32/70\n",
      " - 0s - loss: 0.5525 - acc: 0.7204 - val_loss: 0.5509 - val_acc: 0.7247\n",
      "Epoch 33/70\n",
      " - 0s - loss: 0.5543 - acc: 0.7214 - val_loss: 0.5504 - val_acc: 0.7242\n",
      "Epoch 34/70\n",
      " - 0s - loss: 0.5512 - acc: 0.7228 - val_loss: 0.5493 - val_acc: 0.7263\n",
      "Epoch 35/70\n",
      " - 0s - loss: 0.5563 - acc: 0.7151 - val_loss: 0.5502 - val_acc: 0.7242\n",
      "Epoch 36/70\n",
      " - 0s - loss: 0.5501 - acc: 0.7242 - val_loss: 0.5497 - val_acc: 0.7282\n",
      "Epoch 37/70\n",
      " - 0s - loss: 0.5505 - acc: 0.7178 - val_loss: 0.5493 - val_acc: 0.7263\n",
      "Epoch 38/70\n",
      " - 0s - loss: 0.5487 - acc: 0.7239 - val_loss: 0.5488 - val_acc: 0.7288\n",
      "Epoch 39/70\n",
      " - 0s - loss: 0.5526 - acc: 0.7186 - val_loss: 0.5473 - val_acc: 0.7274\n",
      "Epoch 40/70\n",
      " - 0s - loss: 0.5512 - acc: 0.7209 - val_loss: 0.5483 - val_acc: 0.7261\n",
      "Epoch 41/70\n",
      " - 0s - loss: 0.5497 - acc: 0.7189 - val_loss: 0.5474 - val_acc: 0.7274\n",
      "Epoch 42/70\n",
      " - 0s - loss: 0.5467 - acc: 0.7256 - val_loss: 0.5468 - val_acc: 0.7266\n",
      "Epoch 43/70\n",
      " - 0s - loss: 0.5465 - acc: 0.7237 - val_loss: 0.5461 - val_acc: 0.7296\n",
      "Epoch 44/70\n",
      " - 0s - loss: 0.5464 - acc: 0.7223 - val_loss: 0.5457 - val_acc: 0.7293\n",
      "Epoch 45/70\n",
      " - 0s - loss: 0.5470 - acc: 0.7247 - val_loss: 0.5464 - val_acc: 0.7231\n",
      "Epoch 46/70\n",
      " - 0s - loss: 0.5469 - acc: 0.7247 - val_loss: 0.5464 - val_acc: 0.7274\n",
      "Epoch 47/70\n",
      " - 0s - loss: 0.5449 - acc: 0.7237 - val_loss: 0.5465 - val_acc: 0.7266\n",
      "Epoch 48/70\n",
      " - 0s - loss: 0.5433 - acc: 0.7258 - val_loss: 0.5449 - val_acc: 0.7312\n",
      "Epoch 49/70\n",
      " - 0s - loss: 0.5457 - acc: 0.7234 - val_loss: 0.5443 - val_acc: 0.7293\n",
      "Epoch 50/70\n",
      " - 0s - loss: 0.5408 - acc: 0.7222 - val_loss: 0.5451 - val_acc: 0.7318\n",
      "Epoch 51/70\n",
      " - 0s - loss: 0.5423 - acc: 0.7258 - val_loss: 0.5448 - val_acc: 0.7301\n",
      "Epoch 52/70\n",
      " - 0s - loss: 0.5439 - acc: 0.7263 - val_loss: 0.5440 - val_acc: 0.7301\n",
      "Epoch 53/70\n",
      " - 0s - loss: 0.5417 - acc: 0.7227 - val_loss: 0.5449 - val_acc: 0.7323\n",
      "Epoch 54/70\n",
      " - 0s - loss: 0.5416 - acc: 0.7270 - val_loss: 0.5468 - val_acc: 0.7337\n",
      "Epoch 55/70\n",
      " - 0s - loss: 0.5465 - acc: 0.7220 - val_loss: 0.5436 - val_acc: 0.7323\n",
      "Epoch 56/70\n",
      " - 0s - loss: 0.5374 - acc: 0.7292 - val_loss: 0.5452 - val_acc: 0.7315\n",
      "Epoch 57/70\n",
      " - 0s - loss: 0.5431 - acc: 0.7230 - val_loss: 0.5447 - val_acc: 0.7301\n",
      "Epoch 58/70\n",
      " - 0s - loss: 0.5420 - acc: 0.7282 - val_loss: 0.5460 - val_acc: 0.7315\n",
      "Epoch 59/70\n",
      " - 0s - loss: 0.5377 - acc: 0.7277 - val_loss: 0.5420 - val_acc: 0.7309\n",
      "Epoch 60/70\n",
      " - 0s - loss: 0.5401 - acc: 0.7267 - val_loss: 0.5443 - val_acc: 0.7288\n",
      "Epoch 61/70\n",
      " - 0s - loss: 0.5372 - acc: 0.7294 - val_loss: 0.5422 - val_acc: 0.7309\n",
      "Epoch 62/70\n",
      " - 0s - loss: 0.5366 - acc: 0.7321 - val_loss: 0.5440 - val_acc: 0.7299\n",
      "Epoch 63/70\n",
      " - 0s - loss: 0.5411 - acc: 0.7242 - val_loss: 0.5433 - val_acc: 0.7277\n",
      "Epoch 64/70\n",
      " - 0s - loss: 0.5392 - acc: 0.7235 - val_loss: 0.5419 - val_acc: 0.7312\n",
      "Epoch 65/70\n",
      " - 0s - loss: 0.5395 - acc: 0.7281 - val_loss: 0.5432 - val_acc: 0.7274\n",
      "Epoch 66/70\n",
      " - 0s - loss: 0.5338 - acc: 0.7273 - val_loss: 0.5439 - val_acc: 0.7334\n",
      "Epoch 67/70\n",
      " - 0s - loss: 0.5387 - acc: 0.7315 - val_loss: 0.5433 - val_acc: 0.7328\n",
      "Epoch 68/70\n",
      " - 0s - loss: 0.5345 - acc: 0.7307 - val_loss: 0.5433 - val_acc: 0.7334\n",
      "Epoch 69/70\n",
      " - 0s - loss: 0.5322 - acc: 0.7353 - val_loss: 0.5432 - val_acc: 0.7261\n",
      "Epoch 70/70\n",
      " - 0s - loss: 0.5337 - acc: 0.7286 - val_loss: 0.5418 - val_acc: 0.7328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe095efd5d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-03 15:55:20.963611: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=70, verbose=2, shuffle=True, validation_data = (X_test, Y_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 72.99\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_test)\n",
    "Y_valid = np.array(Y_test)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_test, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
