{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RandomizedLasso\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for calculating delta phi and delta R\n",
    "def process_delta_phi(x):\n",
    "    if x > math.pi:\n",
    "        delta_phi = x - 2*math.pi\n",
    "    elif x < -math.pi:\n",
    "        delta_phi = x + 2*math.pi\n",
    "    else:\n",
    "        delta_phi = x\n",
    "    return delta_phi\n",
    "\n",
    "def calculate_delta_R(phi_1, phi_2, eta_1, eta_2):\n",
    "    x = phi_1 - phi_2\n",
    "    delta_phi = process_delta_phi(x)\n",
    "    delta_eta = eta_1 - eta_2\n",
    "    return math.sqrt(delta_phi**2 + delta_eta**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate training set\n",
    "def generate(df):\n",
    "    \n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number','event_weight','delta_phi','delta_eta','delta_R','invmass','lepton_delta_R_1','lepton_delta_eta_1','lepton_delta_R_2','lepton_delta_eta_2','H']\n",
    "    \n",
    "    for t in range(1,3):\n",
    "        for i in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "    \n",
    "    columns.append('result')\n",
    "    \n",
    "    overall = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6 and df['jet_CSV'][i][2] > 0.8:\n",
    "            checked = 0\n",
    "            for m in range(df['jet_number'][i]):\n",
    "                if df['jet_pT'][i][m] > 20 and np.abs(df['jet_eta'][i][m]) < 2.4:\n",
    "                    checked += 1\n",
    "            if checked < 6:\n",
    "                continue\n",
    "                \n",
    "            count = 0\n",
    "            \n",
    "            #append all the invariant columns\n",
    "            invariants = []\n",
    "            \n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number']:\n",
    "                invariants.append(df[t][i])\n",
    "                \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            invariants.append(product)\n",
    "            \n",
    "            #Loop over possible combinations\n",
    "            for t in range(len(df['jet_pT'][i]) - 1):\n",
    "                for m in range(t+1, len(df['jet_pT'][i])):\n",
    "                \n",
    "                    #initialize variant data column\n",
    "                    variants = []\n",
    "\n",
    "                    #set the jet pair\n",
    "                    jet_pair = (t,m)\n",
    "\n",
    "                    #Delta_phi, delta_eta and delta_R\n",
    "                    x = df['jet_phi'][i][jet_pair[0]] - df['jet_phi'][i][jet_pair[1]]\n",
    "                    delta_phi = process_delta_phi(x)\n",
    "                    delta_eta = df['jet_eta'][i][jet_pair[0]] - df['jet_eta'][i][jet_pair[1]]\n",
    "                    delta_R = math.sqrt(delta_phi**2 + delta_eta**2)\n",
    "\n",
    "                    #invmass\n",
    "                    pt1, pt2 = math.fabs(df['jet_pT'][i][jet_pair[0]]), math.fabs(df['jet_pT'][i][jet_pair[1]])\n",
    "                    pX1, pX2 = pt1 * math.cos(df['jet_phi'][i][jet_pair[0]]), pt2 * math.cos(df['jet_phi'][i][jet_pair[1]])\n",
    "                    pY1, pY2 = pt1 * math.sin(df['jet_phi'][i][jet_pair[0]]), pt2 * math.sin(df['jet_phi'][i][jet_pair[1]])\n",
    "                    pZ1, pZ2 = pt1 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[0]]))), pt2 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[1]])))\n",
    "                    invmass = math.sqrt((df['jet_E'][i][jet_pair[0]] + df['jet_E'][i][jet_pair[1]])**2 - (pX1 + pX2)**2 - (pY1 + pY2)**2 - (pZ1 + pZ2)**2)\n",
    "\n",
    "                    #H\n",
    "                    H = df['jet_pT'][i][jet_pair[0]] + df['jet_pT'][i][jet_pair[1]] + df['lepton_pT'][i]\n",
    "\n",
    "                    #delta_lepton_R\n",
    "                    y_1 = df['jet_phi'][i][jet_pair[0]] - df['lepton_phi'][0]\n",
    "                    delta_phi_lep_1 = process_delta_phi(y_1)\n",
    "                    delta_eta_lep_1 = df['jet_eta'][i][jet_pair[0]] - df['lepton_eta'][0]\n",
    "                    delta_R_lep_1 = math.sqrt(delta_phi_lep_1**2 + delta_eta_lep_1**2)\n",
    "\n",
    "                    y_2 = df['jet_phi'][i][jet_pair[1]] - df['lepton_phi'][0]\n",
    "                    delta_phi_lep_2 = process_delta_phi(y_2)\n",
    "                    delta_eta_lep_2 = df['jet_eta'][i][jet_pair[1]] - df['lepton_eta'][0]\n",
    "                    delta_R_lep_2 = math.sqrt(delta_phi_lep_2**2 + delta_eta_lep_2**2)\n",
    "\n",
    "                    variants += [delta_phi, delta_eta, delta_R, invmass, delta_R_lep_1, delta_eta_lep_1, delta_R_lep_2, delta_eta_lep_2, H]\n",
    "\n",
    "                    for n in [t, m]:\n",
    "                        for k in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "                            variants += [df[k][i][n]]\n",
    "\n",
    "                    #Use Monte Carlo data to classify whether the selected jet is Higgs pair\n",
    "                    phi_1, phi_2 = df['jet_phi'][i][jet_pair[0]], df['jet_phi'][i][jet_pair[1]]\n",
    "                    mt_phi_1, mt_phi_2 = df['addbjet1_phi'][i], df['addbjet2_phi'][i]\n",
    "                    eta_1, eta_2 = df['jet_eta'][i][jet_pair[0]], df['jet_eta'][i][jet_pair[1]]\n",
    "                    mt_eta_1, mt_eta_2 = df['addbjet1_eta'][i], df['addbjet2_eta'][i]\n",
    "\n",
    "                    dR_11 = calculate_delta_R(phi_1, mt_phi_1, eta_1, mt_eta_1)\n",
    "                    dR_12 = calculate_delta_R(phi_1, mt_phi_2, eta_1, mt_eta_2)\n",
    "                    dR_21 = calculate_delta_R(phi_2, mt_phi_1, eta_2, mt_eta_1)\n",
    "                    dR_22 = calculate_delta_R(phi_2, mt_phi_2, eta_2, mt_eta_2)\n",
    "\n",
    "                    variants.append(1 if (dR_11 < 0.4 or dR_12 < 0.4) and (dR_21 < 0.4 or dR_22 < 0.4) else 0)\n",
    "                    count += 1\n",
    "                \n",
    "                    overall.append(invariants + variants)\n",
    "            \n",
    "    print \"Column Length: \", len(overall[0])\n",
    "    print \"Fixed Length: \", len(columns)\n",
    "\n",
    "    train_tree = pd.DataFrame(overall, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Length:  26\n",
      "Fixed Length:  26\n"
     ]
    }
   ],
   "source": [
    "train = generate(dftree_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Export generated training set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('../HYU_data/jet_selection_train.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Imported generated training set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/local/lib/python2.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../HYU_data/jet_selection_train.csv', sep='\\t',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The positive and negative class are very skewed (1:10) - use undersample to keep class balance\n",
    "def under_sample(data):\n",
    "    \n",
    "    pos_events = data[data['result'] == 1]\n",
    "    neg_events = data[data['result'] == 0]\n",
    "    \n",
    "    #Randomize and pick same n number of events\n",
    "    number_pos_events = len(pos_events)  \n",
    "\n",
    "    pos_events = pos_events.reindex(np.random.permutation(pos_events.index))\n",
    "    neg_events = neg_events.reindex(np.random.permutation(neg_events.index))\n",
    "        \n",
    "    undersampled_events = pd.concat([neg_events.head(number_pos_events), pos_events])\n",
    "    X_data_u, scaler = preprocess_data(undersampled_events.drop('result',1))\n",
    "    y_data_u = undersampled_events['result'] \n",
    "\n",
    "    X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(X_data_u, y_data_u, test_size=0.3)\n",
    "    \n",
    "    return X_train_u, X_test_u, y_train_u, y_test_u, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, scaler = under_sample(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(60))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(45))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(15))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.05, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_test_nn = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53708 samples, validate on 23018 samples\n",
      "Epoch 1/70\n",
      " - 3s - loss: 0.5713 - acc: 0.6939 - val_loss: 0.4698 - val_acc: 0.7790\n",
      "Epoch 2/70\n",
      " - 2s - loss: 0.4948 - acc: 0.7650 - val_loss: 0.4618 - val_acc: 0.7847\n",
      "Epoch 3/70\n",
      " - 3s - loss: 0.4831 - acc: 0.7729 - val_loss: 0.4582 - val_acc: 0.7857\n",
      "Epoch 4/70\n",
      " - 3s - loss: 0.4811 - acc: 0.7714 - val_loss: 0.4559 - val_acc: 0.7874\n",
      "Epoch 5/70\n",
      " - 2s - loss: 0.4798 - acc: 0.7730 - val_loss: 0.4538 - val_acc: 0.7895\n",
      "Epoch 6/70\n",
      " - 3s - loss: 0.4747 - acc: 0.7783 - val_loss: 0.4495 - val_acc: 0.7899\n",
      "Epoch 7/70\n",
      " - 3s - loss: 0.4724 - acc: 0.7769 - val_loss: 0.4506 - val_acc: 0.7906\n",
      "Epoch 8/70\n",
      " - 3s - loss: 0.4732 - acc: 0.7775 - val_loss: 0.4485 - val_acc: 0.7925\n",
      "Epoch 9/70\n",
      " - 3s - loss: 0.4722 - acc: 0.7761 - val_loss: 0.4457 - val_acc: 0.7921\n",
      "Epoch 10/70\n",
      " - 3s - loss: 0.4699 - acc: 0.7795 - val_loss: 0.4480 - val_acc: 0.7932\n",
      "Epoch 11/70\n",
      " - 3s - loss: 0.4683 - acc: 0.7795 - val_loss: 0.4448 - val_acc: 0.7944\n",
      "Epoch 12/70\n",
      " - 3s - loss: 0.4678 - acc: 0.7777 - val_loss: 0.4446 - val_acc: 0.7933\n",
      "Epoch 13/70\n",
      " - 3s - loss: 0.4659 - acc: 0.7806 - val_loss: 0.4437 - val_acc: 0.7930\n",
      "Epoch 14/70\n",
      " - 3s - loss: 0.4671 - acc: 0.7793 - val_loss: 0.4457 - val_acc: 0.7931\n",
      "Epoch 15/70\n",
      " - 3s - loss: 0.4673 - acc: 0.7792 - val_loss: 0.4453 - val_acc: 0.7949\n",
      "Epoch 16/70\n",
      " - 3s - loss: 0.4654 - acc: 0.7778 - val_loss: 0.4448 - val_acc: 0.7945\n",
      "Epoch 17/70\n",
      " - 3s - loss: 0.4653 - acc: 0.7803 - val_loss: 0.4444 - val_acc: 0.7957\n",
      "Epoch 18/70\n",
      " - 3s - loss: 0.4642 - acc: 0.7810 - val_loss: 0.4455 - val_acc: 0.7955\n",
      "Epoch 19/70\n",
      " - 3s - loss: 0.4643 - acc: 0.7804 - val_loss: 0.4453 - val_acc: 0.7958\n",
      "Epoch 20/70\n",
      " - 3s - loss: 0.4628 - acc: 0.7816 - val_loss: 0.4425 - val_acc: 0.7962\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.4633 - acc: 0.7813 - val_loss: 0.4476 - val_acc: 0.7932\n",
      "Epoch 22/70\n",
      " - 3s - loss: 0.4615 - acc: 0.7828 - val_loss: 0.4427 - val_acc: 0.7972\n",
      "Epoch 23/70\n",
      " - 3s - loss: 0.4635 - acc: 0.7817 - val_loss: 0.4455 - val_acc: 0.7971\n",
      "Epoch 24/70\n",
      " - 3s - loss: 0.4595 - acc: 0.7835 - val_loss: 0.4443 - val_acc: 0.7984\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.4612 - acc: 0.7830 - val_loss: 0.4419 - val_acc: 0.7978\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.4606 - acc: 0.7815 - val_loss: 0.4425 - val_acc: 0.7963\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.4605 - acc: 0.7832 - val_loss: 0.4422 - val_acc: 0.7965\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.4597 - acc: 0.7834 - val_loss: 0.4418 - val_acc: 0.7960\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.4609 - acc: 0.7831 - val_loss: 0.4395 - val_acc: 0.7970\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.4599 - acc: 0.7837 - val_loss: 0.4395 - val_acc: 0.7983\n",
      "Epoch 31/70\n",
      " - 3s - loss: 0.4600 - acc: 0.7839 - val_loss: 0.4391 - val_acc: 0.7988\n",
      "Epoch 32/70\n",
      " - 3s - loss: 0.4589 - acc: 0.7838 - val_loss: 0.4401 - val_acc: 0.7975\n",
      "Epoch 33/70\n",
      " - 3s - loss: 0.4572 - acc: 0.7851 - val_loss: 0.4379 - val_acc: 0.7985\n",
      "Epoch 34/70\n",
      " - 3s - loss: 0.4594 - acc: 0.7823 - val_loss: 0.4442 - val_acc: 0.7981\n",
      "Epoch 35/70\n",
      " - 3s - loss: 0.4569 - acc: 0.7860 - val_loss: 0.4380 - val_acc: 0.7999\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.4561 - acc: 0.7854 - val_loss: 0.4378 - val_acc: 0.7995\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.4561 - acc: 0.7843 - val_loss: 0.4386 - val_acc: 0.7982\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.4564 - acc: 0.7854 - val_loss: 0.4370 - val_acc: 0.7986\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.4556 - acc: 0.7857 - val_loss: 0.4384 - val_acc: 0.7986\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.4572 - acc: 0.7844 - val_loss: 0.4385 - val_acc: 0.8007\n",
      "Epoch 41/70\n",
      " - 3s - loss: 0.4544 - acc: 0.7859 - val_loss: 0.4393 - val_acc: 0.7982\n",
      "Epoch 42/70\n",
      " - 3s - loss: 0.4546 - acc: 0.7860 - val_loss: 0.4356 - val_acc: 0.8013\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.4562 - acc: 0.7853 - val_loss: 0.4358 - val_acc: 0.7993\n",
      "Epoch 44/70\n",
      " - 3s - loss: 0.4548 - acc: 0.7848 - val_loss: 0.4384 - val_acc: 0.7982\n",
      "Epoch 45/70\n",
      " - 3s - loss: 0.4547 - acc: 0.7860 - val_loss: 0.4363 - val_acc: 0.8002\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.4536 - acc: 0.7871 - val_loss: 0.4357 - val_acc: 0.8007\n",
      "Epoch 47/70\n",
      " - 3s - loss: 0.4553 - acc: 0.7861 - val_loss: 0.4390 - val_acc: 0.7994\n",
      "Epoch 48/70\n",
      " - 3s - loss: 0.4551 - acc: 0.7860 - val_loss: 0.4401 - val_acc: 0.7980\n",
      "Epoch 49/70\n",
      " - 3s - loss: 0.4530 - acc: 0.7863 - val_loss: 0.4355 - val_acc: 0.8007\n",
      "Epoch 50/70\n",
      " - 3s - loss: 0.4510 - acc: 0.7867 - val_loss: 0.4364 - val_acc: 0.8003\n",
      "Epoch 51/70\n",
      " - 3s - loss: 0.4536 - acc: 0.7870 - val_loss: 0.4357 - val_acc: 0.8007\n",
      "Epoch 52/70\n",
      " - 3s - loss: 0.4516 - acc: 0.7869 - val_loss: 0.4339 - val_acc: 0.7994\n",
      "Epoch 53/70\n",
      " - 3s - loss: 0.4527 - acc: 0.7855 - val_loss: 0.4390 - val_acc: 0.8001\n",
      "Epoch 54/70\n",
      " - 3s - loss: 0.4529 - acc: 0.7846 - val_loss: 0.4365 - val_acc: 0.8032\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.4507 - acc: 0.7886 - val_loss: 0.4362 - val_acc: 0.7997\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.4504 - acc: 0.7886 - val_loss: 0.4329 - val_acc: 0.8020\n",
      "Epoch 57/70\n",
      " - 3s - loss: 0.4519 - acc: 0.7869 - val_loss: 0.4319 - val_acc: 0.8005\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.4497 - acc: 0.7886 - val_loss: 0.4325 - val_acc: 0.8008\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.4512 - acc: 0.7871 - val_loss: 0.4338 - val_acc: 0.8030\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.4511 - acc: 0.7879 - val_loss: 0.4320 - val_acc: 0.8017\n",
      "Epoch 61/70\n",
      " - 3s - loss: 0.4498 - acc: 0.7890 - val_loss: 0.4337 - val_acc: 0.8029\n",
      "Epoch 62/70\n",
      " - 3s - loss: 0.4501 - acc: 0.7864 - val_loss: 0.4364 - val_acc: 0.8025\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.4488 - acc: 0.7899 - val_loss: 0.4317 - val_acc: 0.8024\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.4492 - acc: 0.7906 - val_loss: 0.4301 - val_acc: 0.8031\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.4493 - acc: 0.7898 - val_loss: 0.4319 - val_acc: 0.8019\n",
      "Epoch 66/70\n",
      " - 3s - loss: 0.4476 - acc: 0.7901 - val_loss: 0.4311 - val_acc: 0.8031\n",
      "Epoch 67/70\n",
      " - 3s - loss: 0.4482 - acc: 0.7889 - val_loss: 0.4294 - val_acc: 0.8020\n",
      "Epoch 68/70\n",
      " - 3s - loss: 0.4475 - acc: 0.7900 - val_loss: 0.4322 - val_acc: 0.8033\n",
      "Epoch 69/70\n",
      " - 3s - loss: 0.4444 - acc: 0.7926 - val_loss: 0.4310 - val_acc: 0.8045\n",
      "Epoch 70/70\n",
      " - 3s - loss: 0.4469 - acc: 0.7889 - val_loss: 0.4304 - val_acc: 0.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc11a34e250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 20:42:07.161850: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=70, verbose=2, shuffle=True, validation_data = (X_test, Y_test_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Save the computed model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jet_randomforest.h5']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.save') \n",
    "joblib.dump(model, 'jet_selection.h5')\n",
    "joblib.dump(rf, 'jet_randomforest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 81.31\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_test)\n",
    "Y_valid = np.array(Y_test)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_test, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 100.00\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_train)\n",
    "Y_valid = np.array(Y_train)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_train, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_0 = [nn_test[i] for i in range(len(nn_test)) if Y_test.tolist()[i] == 0] \n",
    "result_1 = [nn_test[i] for i in range(len(nn_test)) if Y_test.tolist()[i] == 1]\n",
    "\n",
    "# sns.kdeplot(result_0, label=\"Not Higgs\")\n",
    "# sns.kdeplot(result_1, label=\"Higgs\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767813905223\n"
     ]
    }
   ],
   "source": [
    "result_0_0 = sum([1 for i in result_0 if i[0] > i[1]])\n",
    "print(float(result_0_0) / len(result_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839532041208\n"
     ]
    }
   ],
   "source": [
    "result_1_1 = sum([1 for i in result_1 if i[0] < i[1]])\n",
    "print(float(result_1_1) / len(result_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the Combined Model: 79.83\n"
     ]
    }
   ],
   "source": [
    "nn_test = model.predict(X_test)\n",
    "nn_test = np.array([i[1] for i in nn_test])\n",
    "print(\"Accuracy for the Combined Model: %.2f\" % (accuracy_score(Y_test, nn_test.round()) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
