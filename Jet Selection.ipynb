{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RandomizedLasso\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names, start = 0, stop = 40000)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_delta_phi(x):\n",
    "    if x > math.pi:\n",
    "        delta_phi = x - 2*math.pi\n",
    "    elif x < -math.pi:\n",
    "        delta_phi = x + 2*math.pi\n",
    "    else:\n",
    "        delta_phi = x\n",
    "    return delta_phi\n",
    "\n",
    "def calculate_delta_R(phi_1, phi_2, eta_1, eta_2):\n",
    "    x = phi_1 - phi_2\n",
    "    delta_phi = process_delta_phi(x)\n",
    "    delta_eta = eta_1 - eta_2\n",
    "    return math.sqrt(delta_phi**2 + delta_eta**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(df):\n",
    "    \n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number','event_weight','delta_phi','delta_eta','delta_R','invmass','lepton_delta_R','lepton_delta_eta','H']\n",
    "    \n",
    "    for t in range(1,3):\n",
    "        for i in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "    \n",
    "    columns.append('result')\n",
    "    \n",
    "    overall = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6 and df['jet_CSV'][i][2] > 0.8:\n",
    "            checked = 0\n",
    "            for m in range(df['jet_number'][i]):\n",
    "                if df['jet_pT'][i][m] > 20 and np.abs(df['jet_eta'][i][m]) < 2.4:\n",
    "                    checked += 1\n",
    "            if checked < 6:\n",
    "                continue\n",
    "                \n",
    "            count = 0\n",
    "            \n",
    "            #append all the invariant columns\n",
    "            invariants = []\n",
    "            \n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number']:\n",
    "                invariants.append(df[t][i])\n",
    "                \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            invariants.append(product)\n",
    "            \n",
    "            #Loop over possible combinations\n",
    "            for t in [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3)]:\n",
    "                \n",
    "                #initialize variant data column\n",
    "                variants = []\n",
    "                \n",
    "                #set the jet pair\n",
    "                jet_pair = (t[0],t[1])\n",
    "                \n",
    "                #Delta_phi, delta_eta and delta_R\n",
    "                x = df['jet_phi'][i][jet_pair[0]] - df['jet_phi'][i][jet_pair[1]]\n",
    "                delta_phi = process_delta_phi(x)\n",
    "                delta_eta = df['jet_eta'][i][jet_pair[0]] - df['jet_eta'][i][jet_pair[1]]\n",
    "                delta_R = math.sqrt(delta_phi**2 + delta_eta**2)\n",
    "\n",
    "                #invmass\n",
    "                pt1, pt2 = math.fabs(df['jet_pT'][i][jet_pair[0]]), math.fabs(df['jet_pT'][i][jet_pair[1]])\n",
    "                pX1, pX2 = pt1 * math.cos(df['jet_phi'][i][jet_pair[0]]), pt2 * math.cos(df['jet_phi'][i][jet_pair[1]])\n",
    "                pY1, pY2 = pt1 * math.sin(df['jet_phi'][i][jet_pair[0]]), pt2 * math.sin(df['jet_phi'][i][jet_pair[1]])\n",
    "                pZ1, pZ2 = pt1 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[0]]))), pt2 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[1]])))\n",
    "                invmass = math.sqrt((df['jet_E'][i][jet_pair[0]] + df['jet_E'][i][jet_pair[1]])**2 - (pX1 + pX2)**2 - (pY1 + pY2)**2 - (pZ1 + pZ2)**2)\n",
    "\n",
    "                #H\n",
    "                H = df['jet_pT'][i][jet_pair[0]] + df['jet_pT'][i][jet_pair[1]] + df['lepton_pT'][i]\n",
    "\n",
    "                #delta_lepton_R\n",
    "                y = df['jet_phi'][i][1] - df['lepton_phi'][i]\n",
    "                delta_phi_lep = process_delta_phi(x)\n",
    "                delta_eta_lep = df['jet_eta'][i][1] - df['lepton_eta'][i]\n",
    "                delta_R_lep = math.sqrt(delta_phi_lep**2 + delta_eta_lep**2)\n",
    "\n",
    "                variants += [delta_phi, delta_eta, delta_R, invmass, delta_R_lep, delta_eta_lep, H]\n",
    "                \n",
    "                for m in [t[0], t[1]]:\n",
    "                    for k in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "                        variants += [df[k][i][m]]\n",
    "\n",
    "                phi_1, phi_2 = dftree_bg['jet_phi'][i][t[0]], dftree_bg['jet_phi'][i][t[1]]\n",
    "                mt_phi_1, mt_phi_2 = dftree_bg['addbjet1_phi'][i], dftree_bg['addbjet2_phi'][i]\n",
    "                eta_1, eta_2 = dftree_bg['jet_eta'][i][t[0]], dftree_bg['jet_eta'][i][t[1]]\n",
    "                mt_eta_1, mt_eta_2 = dftree_bg['addbjet1_eta'][i], dftree_bg['addbjet2_eta'][i]\n",
    "\n",
    "                dR_11 = calculate_delta_R(phi_1, mt_phi_1, eta_1, mt_eta_1)\n",
    "                dR_12 = calculate_delta_R(phi_1, mt_phi_2, eta_1, mt_eta_2)\n",
    "                dR_21 = calculate_delta_R(phi_2, mt_phi_1, eta_2, mt_eta_1)\n",
    "                dR_22 = calculate_delta_R(phi_2, mt_phi_2, eta_2, mt_eta_2)\n",
    "\n",
    "                variants.append(1 if (dR_11 < 0.4 or dR_12 < 0.4) and (dR_21 < 0.4 or dR_22 < 0.4) else 0)\n",
    "                count += 1\n",
    "                \n",
    "                overall.append(invariants + variants)\n",
    "            \n",
    "    print \"Column Length: \", len(overall[0])\n",
    "    print \"Fixed Length: \", len(columns)\n",
    "\n",
    "    train_tree = pd.DataFrame(overall, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Length:  24\n",
      "Fixed Length:  24\n"
     ]
    }
   ],
   "source": [
    "train = generate(dftree_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45455\n",
       "1     6145\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(data):\n",
    "    \n",
    "    pos_events = data[data['result'] == 1]\n",
    "    neg_events = data[data['result'] == 0]\n",
    "    \n",
    "    #Randomize and pick same n number of events\n",
    "    number_pos_events = len(pos_events)  \n",
    "\n",
    "    pos_events = pos_events.reindex(np.random.permutation(pos_events.index))\n",
    "    neg_events = neg_events.reindex(np.random.permutation(neg_events.index))\n",
    "        \n",
    "    undersampled_events = pd.concat([neg_events.head(number_pos_events), pos_events])\n",
    "    X_data_u, scaler = preprocess_data(undersampled_events.drop('result',1))\n",
    "    y_data_u = undersampled_events['result'] \n",
    "\n",
    "    X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(X_data_u, y_data_u, test_size=0.3)\n",
    "    \n",
    "    return X_train_u, X_test_u, y_train_u, y_test_u, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, scaler = under_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(60))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(45))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(15))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.05, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_test_nn = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8603 samples, validate on 3687 samples\n",
      "Epoch 1/70\n",
      " - 1s - loss: 0.6813 - acc: 0.5622 - val_loss: 0.6546 - val_acc: 0.6645\n",
      "Epoch 2/70\n",
      " - 0s - loss: 0.6522 - acc: 0.6436 - val_loss: 0.6142 - val_acc: 0.6816\n",
      "Epoch 3/70\n",
      " - 0s - loss: 0.6238 - acc: 0.6637 - val_loss: 0.5913 - val_acc: 0.6981\n",
      "Epoch 4/70\n",
      " - 0s - loss: 0.6107 - acc: 0.6736 - val_loss: 0.5856 - val_acc: 0.6911\n",
      "Epoch 5/70\n",
      " - 0s - loss: 0.6001 - acc: 0.6864 - val_loss: 0.5744 - val_acc: 0.7019\n",
      "Epoch 6/70\n",
      " - 0s - loss: 0.5982 - acc: 0.6808 - val_loss: 0.5710 - val_acc: 0.7030\n",
      "Epoch 7/70\n",
      " - 0s - loss: 0.5896 - acc: 0.6865 - val_loss: 0.5690 - val_acc: 0.7049\n",
      "Epoch 8/70\n",
      " - 0s - loss: 0.5876 - acc: 0.6922 - val_loss: 0.5660 - val_acc: 0.7068\n",
      "Epoch 9/70\n",
      " - 0s - loss: 0.5886 - acc: 0.6943 - val_loss: 0.5645 - val_acc: 0.7095\n",
      "Epoch 10/70\n",
      " - 0s - loss: 0.5840 - acc: 0.6972 - val_loss: 0.5611 - val_acc: 0.7092\n",
      "Epoch 11/70\n",
      " - 0s - loss: 0.5841 - acc: 0.6919 - val_loss: 0.5626 - val_acc: 0.7128\n",
      "Epoch 12/70\n",
      " - 0s - loss: 0.5795 - acc: 0.6993 - val_loss: 0.5592 - val_acc: 0.7136\n",
      "Epoch 13/70\n",
      " - 0s - loss: 0.5804 - acc: 0.6953 - val_loss: 0.5574 - val_acc: 0.7147\n",
      "Epoch 14/70\n",
      " - 0s - loss: 0.5791 - acc: 0.6950 - val_loss: 0.5566 - val_acc: 0.7149\n",
      "Epoch 15/70\n",
      " - 0s - loss: 0.5741 - acc: 0.7003 - val_loss: 0.5570 - val_acc: 0.7106\n",
      "Epoch 16/70\n",
      " - 0s - loss: 0.5697 - acc: 0.7074 - val_loss: 0.5555 - val_acc: 0.7147\n",
      "Epoch 17/70\n",
      " - 0s - loss: 0.5679 - acc: 0.7044 - val_loss: 0.5537 - val_acc: 0.7147\n",
      "Epoch 18/70\n",
      " - 0s - loss: 0.5678 - acc: 0.7052 - val_loss: 0.5511 - val_acc: 0.7163\n",
      "Epoch 19/70\n",
      " - 0s - loss: 0.5677 - acc: 0.7051 - val_loss: 0.5531 - val_acc: 0.7152\n",
      "Epoch 20/70\n",
      " - 0s - loss: 0.5691 - acc: 0.7064 - val_loss: 0.5504 - val_acc: 0.7179\n",
      "Epoch 21/70\n",
      " - 0s - loss: 0.5622 - acc: 0.7113 - val_loss: 0.5485 - val_acc: 0.7201\n",
      "Epoch 22/70\n",
      " - 0s - loss: 0.5659 - acc: 0.7036 - val_loss: 0.5485 - val_acc: 0.7163\n",
      "Epoch 23/70\n",
      " - 0s - loss: 0.5622 - acc: 0.7144 - val_loss: 0.5474 - val_acc: 0.7198\n",
      "Epoch 24/70\n",
      " - 0s - loss: 0.5640 - acc: 0.7125 - val_loss: 0.5469 - val_acc: 0.7185\n",
      "Epoch 25/70\n",
      " - 0s - loss: 0.5597 - acc: 0.7118 - val_loss: 0.5464 - val_acc: 0.7185\n",
      "Epoch 26/70\n",
      " - 0s - loss: 0.5579 - acc: 0.7121 - val_loss: 0.5457 - val_acc: 0.7234\n",
      "Epoch 27/70\n",
      " - 0s - loss: 0.5610 - acc: 0.7129 - val_loss: 0.5435 - val_acc: 0.7215\n",
      "Epoch 28/70\n",
      " - 0s - loss: 0.5601 - acc: 0.7128 - val_loss: 0.5455 - val_acc: 0.7206\n",
      "Epoch 29/70\n",
      " - 0s - loss: 0.5572 - acc: 0.7137 - val_loss: 0.5428 - val_acc: 0.7215\n",
      "Epoch 30/70\n",
      " - 0s - loss: 0.5586 - acc: 0.7186 - val_loss: 0.5426 - val_acc: 0.7212\n",
      "Epoch 31/70\n",
      " - 0s - loss: 0.5552 - acc: 0.7160 - val_loss: 0.5444 - val_acc: 0.7204\n",
      "Epoch 32/70\n",
      " - 0s - loss: 0.5556 - acc: 0.7197 - val_loss: 0.5444 - val_acc: 0.7187\n",
      "Epoch 33/70\n",
      " - 0s - loss: 0.5560 - acc: 0.7142 - val_loss: 0.5444 - val_acc: 0.7182\n",
      "Epoch 34/70\n",
      " - 0s - loss: 0.5544 - acc: 0.7159 - val_loss: 0.5427 - val_acc: 0.7190\n",
      "Epoch 35/70\n",
      " - 0s - loss: 0.5553 - acc: 0.7156 - val_loss: 0.5441 - val_acc: 0.7193\n",
      "Epoch 36/70\n",
      " - 0s - loss: 0.5520 - acc: 0.7172 - val_loss: 0.5427 - val_acc: 0.7201\n",
      "Epoch 37/70\n",
      " - 0s - loss: 0.5570 - acc: 0.7142 - val_loss: 0.5413 - val_acc: 0.7204\n",
      "Epoch 38/70\n",
      " - 0s - loss: 0.5521 - acc: 0.7167 - val_loss: 0.5410 - val_acc: 0.7212\n",
      "Epoch 39/70\n",
      " - 0s - loss: 0.5518 - acc: 0.7218 - val_loss: 0.5419 - val_acc: 0.7206\n",
      "Epoch 40/70\n",
      " - 0s - loss: 0.5497 - acc: 0.7218 - val_loss: 0.5406 - val_acc: 0.7261\n",
      "Epoch 41/70\n",
      " - 0s - loss: 0.5504 - acc: 0.7195 - val_loss: 0.5397 - val_acc: 0.7263\n",
      "Epoch 42/70\n",
      " - 0s - loss: 0.5481 - acc: 0.7186 - val_loss: 0.5428 - val_acc: 0.7198\n",
      "Epoch 43/70\n",
      " - 0s - loss: 0.5502 - acc: 0.7200 - val_loss: 0.5436 - val_acc: 0.7271\n",
      "Epoch 44/70\n",
      " - 0s - loss: 0.5481 - acc: 0.7218 - val_loss: 0.5426 - val_acc: 0.7280\n",
      "Epoch 45/70\n",
      " - 0s - loss: 0.5503 - acc: 0.7137 - val_loss: 0.5408 - val_acc: 0.7307\n",
      "Epoch 46/70\n",
      " - 0s - loss: 0.5454 - acc: 0.7246 - val_loss: 0.5395 - val_acc: 0.7269\n",
      "Epoch 47/70\n",
      " - 0s - loss: 0.5499 - acc: 0.7238 - val_loss: 0.5412 - val_acc: 0.7282\n",
      "Epoch 48/70\n",
      " - 0s - loss: 0.5466 - acc: 0.7201 - val_loss: 0.5396 - val_acc: 0.7225\n",
      "Epoch 49/70\n",
      " - 0s - loss: 0.5471 - acc: 0.7249 - val_loss: 0.5394 - val_acc: 0.7261\n",
      "Epoch 50/70\n",
      " - 0s - loss: 0.5421 - acc: 0.7278 - val_loss: 0.5441 - val_acc: 0.7290\n",
      "Epoch 51/70\n",
      " - 0s - loss: 0.5446 - acc: 0.7250 - val_loss: 0.5434 - val_acc: 0.7228\n",
      "Epoch 52/70\n",
      " - 0s - loss: 0.5400 - acc: 0.7287 - val_loss: 0.5407 - val_acc: 0.7312\n",
      "Epoch 53/70\n",
      " - 0s - loss: 0.5463 - acc: 0.7223 - val_loss: 0.5402 - val_acc: 0.7274\n",
      "Epoch 54/70\n",
      " - 0s - loss: 0.5468 - acc: 0.7250 - val_loss: 0.5391 - val_acc: 0.7277\n",
      "Epoch 55/70\n",
      " - 0s - loss: 0.5429 - acc: 0.7236 - val_loss: 0.5374 - val_acc: 0.7309\n",
      "Epoch 56/70\n",
      " - 0s - loss: 0.5430 - acc: 0.7245 - val_loss: 0.5391 - val_acc: 0.7288\n",
      "Epoch 57/70\n",
      " - 0s - loss: 0.5444 - acc: 0.7260 - val_loss: 0.5365 - val_acc: 0.7296\n",
      "Epoch 58/70\n",
      " - 0s - loss: 0.5405 - acc: 0.7295 - val_loss: 0.5381 - val_acc: 0.7318\n",
      "Epoch 59/70\n",
      " - 0s - loss: 0.5447 - acc: 0.7260 - val_loss: 0.5371 - val_acc: 0.7266\n",
      "Epoch 60/70\n",
      " - 0s - loss: 0.5397 - acc: 0.7244 - val_loss: 0.5378 - val_acc: 0.7296\n",
      "Epoch 61/70\n",
      " - 0s - loss: 0.5433 - acc: 0.7303 - val_loss: 0.5378 - val_acc: 0.7269\n",
      "Epoch 62/70\n",
      " - 0s - loss: 0.5415 - acc: 0.7271 - val_loss: 0.5395 - val_acc: 0.7266\n",
      "Epoch 63/70\n",
      " - 0s - loss: 0.5397 - acc: 0.7290 - val_loss: 0.5383 - val_acc: 0.7274\n",
      "Epoch 64/70\n",
      " - 0s - loss: 0.5383 - acc: 0.7290 - val_loss: 0.5379 - val_acc: 0.7301\n",
      "Epoch 65/70\n",
      " - 0s - loss: 0.5417 - acc: 0.7251 - val_loss: 0.5374 - val_acc: 0.7244\n",
      "Epoch 66/70\n",
      " - 0s - loss: 0.5362 - acc: 0.7306 - val_loss: 0.5395 - val_acc: 0.7225\n",
      "Epoch 67/70\n",
      " - 0s - loss: 0.5402 - acc: 0.7251 - val_loss: 0.5365 - val_acc: 0.7296\n",
      "Epoch 68/70\n",
      " - 0s - loss: 0.5392 - acc: 0.7274 - val_loss: 0.5386 - val_acc: 0.7299\n",
      "Epoch 69/70\n",
      " - 0s - loss: 0.5325 - acc: 0.7300 - val_loss: 0.5374 - val_acc: 0.7315\n",
      "Epoch 70/70\n",
      " - 0s - loss: 0.5359 - acc: 0.7300 - val_loss: 0.5378 - val_acc: 0.7288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa344048950>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-04 19:14:01.574694: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=70, verbose=2, shuffle=True, validation_data = (X_test, Y_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.save') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 72.99\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_test)\n",
    "Y_valid = np.array(Y_test)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_test, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
