{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RandomizedLasso\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names, start = 0, stop = 40000)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_delta_phi(x):\n",
    "    if x > math.pi:\n",
    "        delta_phi = x - 2*math.pi\n",
    "    elif x < -math.pi:\n",
    "        delta_phi = x + 2*math.pi\n",
    "    else:\n",
    "        delta_phi = x\n",
    "    return delta_phi\n",
    "\n",
    "def calculate_delta_R(phi_1, phi_2, eta_1, eta_2):\n",
    "    x = phi_1 - phi_2\n",
    "    delta_phi = process_delta_phi(x)\n",
    "    delta_eta = eta_1 - eta_2\n",
    "    return math.sqrt(delta_phi**2 + delta_eta**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(df):\n",
    "    \n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number','event_weight','delta_phi','delta_eta','delta_R','invmass','lepton_delta_R','lepton_delta_eta','H']\n",
    "    \n",
    "    for t in range(1,3):\n",
    "        for i in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "    \n",
    "    columns.append('result')\n",
    "    \n",
    "    overall = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6 and df['jet_CSV'][i][2] > 0.8:\n",
    "            checked = 0\n",
    "            for m in range(df['jet_number'][i]):\n",
    "                if df['jet_pT'][i][m] > 20 and np.abs(dftree_bg['jet_eta'][i][m]) < 2.4:\n",
    "                    checked += 1\n",
    "            if checked < 6:\n",
    "                continue\n",
    "                \n",
    "            count = 0\n",
    "            \n",
    "            #append all the invariant columns\n",
    "            invariants = []\n",
    "            \n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number']:\n",
    "                invariants.append(df[t][i])\n",
    "                \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            invariants.append(product)\n",
    "            \n",
    "            #Loop over possible combinations\n",
    "            for t in [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3)]:\n",
    "                \n",
    "                #initialize variant data column\n",
    "                variants = []\n",
    "                \n",
    "                #set the jet pair\n",
    "                jet_pair = (t[0],t[1])\n",
    "                \n",
    "                #Delta_phi, delta_eta and delta_R\n",
    "                x = df['jet_phi'][i][jet_pair[0]] - df['jet_phi'][i][jet_pair[1]]\n",
    "                delta_phi = process_delta_phi(x)\n",
    "                delta_eta = df['jet_eta'][i][jet_pair[0]] - df['jet_eta'][i][jet_pair[1]]\n",
    "                delta_R = math.sqrt(delta_phi**2 + delta_eta**2)\n",
    "\n",
    "                #invmass\n",
    "                pt1, pt2 = math.fabs(df['jet_pT'][i][jet_pair[0]]), math.fabs(df['jet_pT'][i][jet_pair[1]])\n",
    "                pX1, pX2 = pt1 * math.cos(df['jet_phi'][i][jet_pair[0]]), pt2 * math.cos(df['jet_phi'][i][jet_pair[1]])\n",
    "                pY1, pY2 = pt1 * math.sin(df['jet_phi'][i][jet_pair[0]]), pt2 * math.sin(df['jet_phi'][i][jet_pair[1]])\n",
    "                pZ1, pZ2 = pt1 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[0]]))), pt2 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[1]])))\n",
    "                invmass = math.sqrt((df['jet_E'][i][jet_pair[0]] + df['jet_E'][i][jet_pair[1]])**2 - (pX1 + pX2)**2 - (pY1 + pY2)**2 - (pZ1 + pZ2)**2)\n",
    "\n",
    "                #H\n",
    "                H = df['jet_pT'][i][jet_pair[0]] + df['jet_pT'][i][jet_pair[1]] + df['lepton_pT'][i]\n",
    "\n",
    "                #delta_lepton_R\n",
    "                y = df['jet_phi'][i][1] - df['lepton_phi'][i]\n",
    "                delta_phi_lep = process_delta_phi(x)\n",
    "                delta_eta_lep = df['jet_eta'][i][1] - df['lepton_eta'][i]\n",
    "                delta_R_lep = math.sqrt(delta_phi_lep**2 + delta_eta_lep**2)\n",
    "\n",
    "                variants += [delta_phi, delta_eta, delta_R, invmass, delta_R_lep, delta_eta_lep, H]\n",
    "                \n",
    "                for m in [t[0], t[1]]:\n",
    "                    for k in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "                        variants += [df[k][i][m]]\n",
    "\n",
    "                phi_1, phi_2 = dftree_bg['jet_phi'][i][t[0]], dftree_bg['jet_phi'][i][t[1]]\n",
    "                mt_phi_1, mt_phi_2 = dftree_bg['addbjet1_phi'][i], dftree_bg['addbjet2_phi'][i]\n",
    "                eta_1, eta_2 = dftree_bg['jet_eta'][i][t[0]], dftree_bg['jet_eta'][i][t[1]]\n",
    "                mt_eta_1, mt_eta_2 = dftree_bg['addbjet1_eta'][i], dftree_bg['addbjet2_eta'][i]\n",
    "\n",
    "                dR_11 = calculate_delta_R(phi_1, mt_phi_1, eta_1, mt_eta_1)\n",
    "                dR_12 = calculate_delta_R(phi_1, mt_phi_2, eta_1, mt_eta_2)\n",
    "                dR_21 = calculate_delta_R(phi_2, mt_phi_1, eta_2, mt_eta_1)\n",
    "                dR_22 = calculate_delta_R(phi_2, mt_phi_2, eta_2, mt_eta_2)\n",
    "\n",
    "                variants.append(1 if (dR_11 < 0.4 or dR_12 < 0.4) and (dR_21 < 0.4 or dR_22 < 0.4) else 0)\n",
    "                count += 1\n",
    "                \n",
    "                overall.append(invariants + variants)\n",
    "            \n",
    "    print \"Column Length: \", len(overall[0])\n",
    "    print \"Fixed Length: \", len(columns)\n",
    "\n",
    "    train_tree = pd.DataFrame(overall, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Length:  24\n",
      "Fixed Length:  24\n"
     ]
    }
   ],
   "source": [
    "train = generate(dftree_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45455\n",
       "1     6145\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(data):\n",
    "    \n",
    "    pos_events = data[data['result'] == 1]\n",
    "    neg_events = data[data['result'] == 0]\n",
    "    \n",
    "    #Randomize and pick same n number of events\n",
    "    number_pos_events = len(pos_events)  \n",
    "\n",
    "    pos_events = pos_events.reindex(np.random.permutation(pos_events.index))\n",
    "    neg_events = neg_events.reindex(np.random.permutation(neg_events.index))\n",
    "        \n",
    "    undersampled_events = pd.concat([neg_events.head(number_pos_events), pos_events])\n",
    "    X_data_u, scaler = preprocess_data(undersampled_events.drop('result',1))\n",
    "    y_data_u = undersampled_events['result'] \n",
    "\n",
    "    X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(X_data_u, y_data_u, test_size=0.3)\n",
    "    \n",
    "    return X_train_u, X_test_u, y_train_u, y_test_u, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, scaler = under_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(60))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(45))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(15))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.05, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_test_nn = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8603 samples, validate on 3687 samples\n",
      "Epoch 1/70\n",
      " - 1s - loss: 0.6831 - acc: 0.5593 - val_loss: 0.6560 - val_acc: 0.6368\n",
      "Epoch 2/70\n",
      " - 0s - loss: 0.6439 - acc: 0.6300 - val_loss: 0.6112 - val_acc: 0.6675\n",
      "Epoch 3/70\n",
      " - 0s - loss: 0.6193 - acc: 0.6591 - val_loss: 0.5927 - val_acc: 0.6813\n",
      "Epoch 4/70\n",
      " - 0s - loss: 0.6044 - acc: 0.6750 - val_loss: 0.5816 - val_acc: 0.6884\n",
      "Epoch 5/70\n",
      " - 0s - loss: 0.5981 - acc: 0.6885 - val_loss: 0.5803 - val_acc: 0.6938\n",
      "Epoch 6/70\n",
      " - 0s - loss: 0.5918 - acc: 0.6830 - val_loss: 0.5781 - val_acc: 0.6949\n",
      "Epoch 7/70\n",
      " - 0s - loss: 0.5930 - acc: 0.6841 - val_loss: 0.5728 - val_acc: 0.7000\n",
      "Epoch 8/70\n",
      " - 0s - loss: 0.5836 - acc: 0.6959 - val_loss: 0.5734 - val_acc: 0.7033\n",
      "Epoch 9/70\n",
      " - 0s - loss: 0.5819 - acc: 0.6929 - val_loss: 0.5694 - val_acc: 0.7046\n",
      "Epoch 10/70\n",
      " - 0s - loss: 0.5796 - acc: 0.6970 - val_loss: 0.5682 - val_acc: 0.7041\n",
      "Epoch 11/70\n",
      " - 0s - loss: 0.5820 - acc: 0.6970 - val_loss: 0.5662 - val_acc: 0.7044\n",
      "Epoch 12/70\n",
      " - 0s - loss: 0.5799 - acc: 0.7013 - val_loss: 0.5681 - val_acc: 0.7052\n",
      "Epoch 13/70\n",
      " - 0s - loss: 0.5814 - acc: 0.6959 - val_loss: 0.5642 - val_acc: 0.7074\n",
      "Epoch 14/70\n",
      " - 0s - loss: 0.5752 - acc: 0.7003 - val_loss: 0.5617 - val_acc: 0.7055\n",
      "Epoch 15/70\n",
      " - 0s - loss: 0.5792 - acc: 0.7009 - val_loss: 0.5613 - val_acc: 0.7092\n",
      "Epoch 16/70\n",
      " - 0s - loss: 0.5704 - acc: 0.7096 - val_loss: 0.5596 - val_acc: 0.7098\n",
      "Epoch 17/70\n",
      " - 0s - loss: 0.5695 - acc: 0.7073 - val_loss: 0.5575 - val_acc: 0.7139\n",
      "Epoch 18/70\n",
      " - 0s - loss: 0.5690 - acc: 0.7068 - val_loss: 0.5584 - val_acc: 0.7076\n",
      "Epoch 19/70\n",
      " - 0s - loss: 0.5724 - acc: 0.7086 - val_loss: 0.5602 - val_acc: 0.7117\n",
      "Epoch 20/70\n",
      " - 0s - loss: 0.5700 - acc: 0.7032 - val_loss: 0.5579 - val_acc: 0.7136\n",
      "Epoch 21/70\n",
      " - 0s - loss: 0.5662 - acc: 0.7073 - val_loss: 0.5546 - val_acc: 0.7139\n",
      "Epoch 22/70\n",
      " - 0s - loss: 0.5680 - acc: 0.7064 - val_loss: 0.5556 - val_acc: 0.7130\n",
      "Epoch 23/70\n",
      " - 0s - loss: 0.5724 - acc: 0.7023 - val_loss: 0.5589 - val_acc: 0.7095\n",
      "Epoch 24/70\n",
      " - 0s - loss: 0.5658 - acc: 0.7104 - val_loss: 0.5531 - val_acc: 0.7158\n",
      "Epoch 25/70\n",
      " - 0s - loss: 0.5599 - acc: 0.7120 - val_loss: 0.5507 - val_acc: 0.7166\n",
      "Epoch 26/70\n",
      " - 0s - loss: 0.5609 - acc: 0.7131 - val_loss: 0.5527 - val_acc: 0.7122\n",
      "Epoch 27/70\n",
      " - 0s - loss: 0.5659 - acc: 0.7114 - val_loss: 0.5492 - val_acc: 0.7187\n",
      "Epoch 28/70\n",
      " - 0s - loss: 0.5613 - acc: 0.7161 - val_loss: 0.5515 - val_acc: 0.7133\n",
      "Epoch 29/70\n",
      " - 0s - loss: 0.5617 - acc: 0.7123 - val_loss: 0.5513 - val_acc: 0.7139\n",
      "Epoch 30/70\n",
      " - 0s - loss: 0.5609 - acc: 0.7158 - val_loss: 0.5491 - val_acc: 0.7152\n",
      "Epoch 31/70\n",
      " - 0s - loss: 0.5608 - acc: 0.7153 - val_loss: 0.5479 - val_acc: 0.7174\n",
      "Epoch 32/70\n",
      " - 0s - loss: 0.5620 - acc: 0.7148 - val_loss: 0.5476 - val_acc: 0.7177\n",
      "Epoch 33/70\n",
      " - 0s - loss: 0.5555 - acc: 0.7211 - val_loss: 0.5477 - val_acc: 0.7171\n",
      "Epoch 34/70\n",
      " - 0s - loss: 0.5577 - acc: 0.7164 - val_loss: 0.5479 - val_acc: 0.7171\n",
      "Epoch 35/70\n",
      " - 0s - loss: 0.5632 - acc: 0.7128 - val_loss: 0.5510 - val_acc: 0.7158\n",
      "Epoch 36/70\n",
      " - 0s - loss: 0.5558 - acc: 0.7144 - val_loss: 0.5527 - val_acc: 0.7166\n",
      "Epoch 37/70\n",
      " - 0s - loss: 0.5583 - acc: 0.7144 - val_loss: 0.5491 - val_acc: 0.7152\n",
      "Epoch 38/70\n",
      " - 0s - loss: 0.5564 - acc: 0.7186 - val_loss: 0.5498 - val_acc: 0.7177\n",
      "Epoch 39/70\n",
      " - 0s - loss: 0.5564 - acc: 0.7194 - val_loss: 0.5459 - val_acc: 0.7204\n",
      "Epoch 40/70\n",
      " - 0s - loss: 0.5557 - acc: 0.7159 - val_loss: 0.5504 - val_acc: 0.7147\n",
      "Epoch 41/70\n",
      " - 0s - loss: 0.5524 - acc: 0.7193 - val_loss: 0.5457 - val_acc: 0.7220\n",
      "Epoch 42/70\n",
      " - 0s - loss: 0.5535 - acc: 0.7213 - val_loss: 0.5434 - val_acc: 0.7234\n",
      "Epoch 43/70\n",
      " - 0s - loss: 0.5527 - acc: 0.7201 - val_loss: 0.5483 - val_acc: 0.7128\n",
      "Epoch 44/70\n",
      " - 0s - loss: 0.5529 - acc: 0.7208 - val_loss: 0.5489 - val_acc: 0.7174\n",
      "Epoch 45/70\n",
      " - 0s - loss: 0.5532 - acc: 0.7208 - val_loss: 0.5444 - val_acc: 0.7212\n",
      "Epoch 46/70\n",
      " - 0s - loss: 0.5553 - acc: 0.7181 - val_loss: 0.5466 - val_acc: 0.7179\n",
      "Epoch 47/70\n",
      " - 0s - loss: 0.5503 - acc: 0.7216 - val_loss: 0.5448 - val_acc: 0.7174\n",
      "Epoch 48/70\n",
      " - 0s - loss: 0.5506 - acc: 0.7239 - val_loss: 0.5460 - val_acc: 0.7193\n",
      "Epoch 49/70\n",
      " - 0s - loss: 0.5515 - acc: 0.7178 - val_loss: 0.5458 - val_acc: 0.7144\n",
      "Epoch 50/70\n",
      " - 0s - loss: 0.5514 - acc: 0.7221 - val_loss: 0.5418 - val_acc: 0.7228\n",
      "Epoch 51/70\n",
      " - 0s - loss: 0.5497 - acc: 0.7256 - val_loss: 0.5438 - val_acc: 0.7187\n",
      "Epoch 52/70\n",
      " - 0s - loss: 0.5486 - acc: 0.7196 - val_loss: 0.5426 - val_acc: 0.7217\n",
      "Epoch 53/70\n",
      " - 0s - loss: 0.5438 - acc: 0.7247 - val_loss: 0.5406 - val_acc: 0.7258\n",
      "Epoch 54/70\n",
      " - 0s - loss: 0.5496 - acc: 0.7222 - val_loss: 0.5416 - val_acc: 0.7234\n",
      "Epoch 55/70\n",
      " - 0s - loss: 0.5456 - acc: 0.7263 - val_loss: 0.5429 - val_acc: 0.7201\n",
      "Epoch 56/70\n",
      " - 0s - loss: 0.5487 - acc: 0.7217 - val_loss: 0.5429 - val_acc: 0.7198\n",
      "Epoch 57/70\n",
      " - 0s - loss: 0.5449 - acc: 0.7228 - val_loss: 0.5388 - val_acc: 0.7234\n",
      "Epoch 58/70\n",
      " - 0s - loss: 0.5474 - acc: 0.7229 - val_loss: 0.5416 - val_acc: 0.7220\n",
      "Epoch 59/70\n",
      " - 0s - loss: 0.5420 - acc: 0.7258 - val_loss: 0.5425 - val_acc: 0.7234\n",
      "Epoch 60/70\n",
      " - 0s - loss: 0.5431 - acc: 0.7272 - val_loss: 0.5410 - val_acc: 0.7225\n",
      "Epoch 61/70\n",
      " - 0s - loss: 0.5427 - acc: 0.7246 - val_loss: 0.5390 - val_acc: 0.7258\n",
      "Epoch 62/70\n",
      " - 0s - loss: 0.5427 - acc: 0.7288 - val_loss: 0.5395 - val_acc: 0.7247\n",
      "Epoch 63/70\n",
      " - 0s - loss: 0.5467 - acc: 0.7218 - val_loss: 0.5394 - val_acc: 0.7263\n",
      "Epoch 64/70\n",
      " - 0s - loss: 0.5406 - acc: 0.7304 - val_loss: 0.5391 - val_acc: 0.7250\n",
      "Epoch 65/70\n",
      " - 0s - loss: 0.5422 - acc: 0.7289 - val_loss: 0.5370 - val_acc: 0.7269\n",
      "Epoch 66/70\n",
      " - 0s - loss: 0.5419 - acc: 0.7266 - val_loss: 0.5440 - val_acc: 0.7166\n",
      "Epoch 67/70\n",
      " - 0s - loss: 0.5422 - acc: 0.7286 - val_loss: 0.5372 - val_acc: 0.7255\n",
      "Epoch 68/70\n",
      " - 0s - loss: 0.5425 - acc: 0.7244 - val_loss: 0.5390 - val_acc: 0.7234\n",
      "Epoch 69/70\n",
      " - 0s - loss: 0.5441 - acc: 0.7256 - val_loss: 0.5390 - val_acc: 0.7228\n",
      "Epoch 70/70\n",
      " - 0s - loss: 0.5415 - acc: 0.7271 - val_loss: 0.5398 - val_acc: 0.7187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7f83c8890>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-04 17:50:31.320035: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=70, verbose=2, shuffle=True, validation_data = (X_test, Y_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.save') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 72.99\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_test)\n",
    "Y_valid = np.array(Y_test)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_test, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
