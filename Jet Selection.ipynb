{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RandomizedLasso\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_delta_phi(x):\n",
    "    if x > math.pi:\n",
    "        delta_phi = x - 2*math.pi\n",
    "    elif x < -math.pi:\n",
    "        delta_phi = x + 2*math.pi\n",
    "    else:\n",
    "        delta_phi = x\n",
    "    return delta_phi\n",
    "\n",
    "def calculate_delta_R(phi_1, phi_2, eta_1, eta_2):\n",
    "    x = phi_1 - phi_2\n",
    "    delta_phi = process_delta_phi(x)\n",
    "    delta_eta = eta_1 - eta_2\n",
    "    return math.sqrt(delta_phi**2 + delta_eta**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(df):\n",
    "    \n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number','event_weight','delta_phi','delta_eta','delta_R','invmass','lepton_delta_R_1','lepton_delta_eta_1','lepton_delta_R_2','lepton_delta_eta_2','H']\n",
    "    \n",
    "    for t in range(1,3):\n",
    "        for i in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "    \n",
    "    columns.append('result')\n",
    "    \n",
    "    overall = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6 and df['jet_CSV'][i][2] > 0.8:\n",
    "            checked = 0\n",
    "            for m in range(df['jet_number'][i]):\n",
    "                if df['jet_pT'][i][m] > 20 and np.abs(df['jet_eta'][i][m]) < 2.4:\n",
    "                    checked += 1\n",
    "            if checked < 6:\n",
    "                continue\n",
    "                \n",
    "            count = 0\n",
    "            \n",
    "            #append all the invariant columns\n",
    "            invariants = []\n",
    "            \n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_E','MET','MET_phi','jet_number']:\n",
    "                invariants.append(df[t][i])\n",
    "                \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            invariants.append(product)\n",
    "            \n",
    "            #Loop over possible combinations\n",
    "            for t in range(len(df['jet_pT'][i]) - 1):\n",
    "                for m in range(t+1, len(df['jet_pT'][i])):\n",
    "                \n",
    "                    #initialize variant data column\n",
    "                    variants = []\n",
    "\n",
    "                    #set the jet pair\n",
    "                    jet_pair = (t,m)\n",
    "\n",
    "                    #Delta_phi, delta_eta and delta_R\n",
    "                    x = df['jet_phi'][i][jet_pair[0]] - df['jet_phi'][i][jet_pair[1]]\n",
    "                    delta_phi = process_delta_phi(x)\n",
    "                    delta_eta = df['jet_eta'][i][jet_pair[0]] - df['jet_eta'][i][jet_pair[1]]\n",
    "                    delta_R = math.sqrt(delta_phi**2 + delta_eta**2)\n",
    "\n",
    "                    #invmass\n",
    "                    pt1, pt2 = math.fabs(df['jet_pT'][i][jet_pair[0]]), math.fabs(df['jet_pT'][i][jet_pair[1]])\n",
    "                    pX1, pX2 = pt1 * math.cos(df['jet_phi'][i][jet_pair[0]]), pt2 * math.cos(df['jet_phi'][i][jet_pair[1]])\n",
    "                    pY1, pY2 = pt1 * math.sin(df['jet_phi'][i][jet_pair[0]]), pt2 * math.sin(df['jet_phi'][i][jet_pair[1]])\n",
    "                    pZ1, pZ2 = pt1 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[0]]))), pt2 / math.tan(2.0 * math.atan(math.exp(-df['jet_eta'][i][jet_pair[1]])))\n",
    "                    invmass = math.sqrt((df['jet_E'][i][jet_pair[0]] + df['jet_E'][i][jet_pair[1]])**2 - (pX1 + pX2)**2 - (pY1 + pY2)**2 - (pZ1 + pZ2)**2)\n",
    "\n",
    "                    #H\n",
    "                    H = df['jet_pT'][i][jet_pair[0]] + df['jet_pT'][i][jet_pair[1]] + df['lepton_pT'][i]\n",
    "\n",
    "                    #delta_lepton_R\n",
    "                    y_1 = df['jet_phi'][i][jet_pair[0]] - df['lepton_phi'][0]\n",
    "                    delta_phi_lep_1 = process_delta_phi(y_1)\n",
    "                    delta_eta_lep_1 = df['jet_eta'][i][jet_pair[0]] - df['lepton_eta'][0]\n",
    "                    delta_R_lep_1 = math.sqrt(delta_phi_lep_1**2 + delta_eta_lep_1**2)\n",
    "\n",
    "                    y_2 = df['jet_phi'][i][jet_pair[1]] - df['lepton_phi'][0]\n",
    "                    delta_phi_lep_2 = process_delta_phi(y_2)\n",
    "                    delta_eta_lep_2 = df['jet_eta'][i][jet_pair[1]] - df['lepton_eta'][0]\n",
    "                    delta_R_lep_2 = math.sqrt(delta_phi_lep_2**2 + delta_eta_lep_2**2)\n",
    "\n",
    "                    variants += [delta_phi, delta_eta, delta_R, invmass, delta_R_lep_1, delta_eta_lep_1, delta_R_lep_2, delta_eta_lep_2, H]\n",
    "\n",
    "                    for n in [t, m]:\n",
    "                        for k in ['jet_pT','jet_eta','jet_E','jet_CvsB']:\n",
    "                            variants += [df[k][i][n]]\n",
    "\n",
    "                    phi_1, phi_2 = dftree_bg['jet_phi'][i][jet_pair[0]], dftree_bg['jet_phi'][i][jet_pair[1]]\n",
    "                    mt_phi_1, mt_phi_2 = dftree_bg['addbjet1_phi'][i], dftree_bg['addbjet2_phi'][i]\n",
    "                    eta_1, eta_2 = dftree_bg['jet_eta'][i][jet_pair[0]], dftree_bg['jet_eta'][i][jet_pair[1]]\n",
    "                    mt_eta_1, mt_eta_2 = dftree_bg['addbjet1_eta'][i], dftree_bg['addbjet2_eta'][i]\n",
    "\n",
    "                    dR_11 = calculate_delta_R(phi_1, mt_phi_1, eta_1, mt_eta_1)\n",
    "                    dR_12 = calculate_delta_R(phi_1, mt_phi_2, eta_1, mt_eta_2)\n",
    "                    dR_21 = calculate_delta_R(phi_2, mt_phi_1, eta_2, mt_eta_1)\n",
    "                    dR_22 = calculate_delta_R(phi_2, mt_phi_2, eta_2, mt_eta_2)\n",
    "\n",
    "                    variants.append(1 if (dR_11 < 0.4 or dR_12 < 0.4) and (dR_21 < 0.4 or dR_22 < 0.4) else 0)\n",
    "                    count += 1\n",
    "                \n",
    "                    overall.append(invariants + variants)\n",
    "            \n",
    "    print \"Column Length: \", len(overall[0])\n",
    "    print \"Fixed Length: \", len(columns)\n",
    "\n",
    "    train_tree = pd.DataFrame(overall, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Length:  26\n",
      "Fixed Length:  26\n"
     ]
    }
   ],
   "source": [
    "train = generate(dftree_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../HYU_data/jet_selection_train.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('../HYU_data/jet_selection_train.csv', sep='\\t',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(data):\n",
    "    \n",
    "    pos_events = data[data['result'] == 1]\n",
    "    neg_events = data[data['result'] == 0]\n",
    "    \n",
    "    #Randomize and pick same n number of events\n",
    "    number_pos_events = len(pos_events)  \n",
    "\n",
    "    pos_events = pos_events.reindex(np.random.permutation(pos_events.index))\n",
    "    neg_events = neg_events.reindex(np.random.permutation(neg_events.index))\n",
    "        \n",
    "    undersampled_events = pd.concat([neg_events.head(number_pos_events), pos_events])\n",
    "    X_data_u, scaler = preprocess_data(undersampled_events.drop('result',1))\n",
    "    y_data_u = undersampled_events['result'] \n",
    "\n",
    "    X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(X_data_u, y_data_u, test_size=0.3)\n",
    "    \n",
    "    return X_train_u, X_test_u, y_train_u, y_test_u, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, scaler = under_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(60))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(45))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(15))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.05, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_test_nn = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53708 samples, validate on 23018 samples\n",
      "Epoch 1/70\n",
      " - 3s - loss: 0.5412 - acc: 0.7290 - val_loss: 0.4658 - val_acc: 0.7843\n",
      "Epoch 2/70\n",
      " - 2s - loss: 0.4925 - acc: 0.7668 - val_loss: 0.4575 - val_acc: 0.7871\n",
      "Epoch 3/70\n",
      " - 2s - loss: 0.4833 - acc: 0.7716 - val_loss: 0.4537 - val_acc: 0.7880\n",
      "Epoch 4/70\n",
      " - 3s - loss: 0.4810 - acc: 0.7723 - val_loss: 0.4563 - val_acc: 0.7894\n",
      "Epoch 5/70\n",
      " - 2s - loss: 0.4758 - acc: 0.7747 - val_loss: 0.4500 - val_acc: 0.7908\n",
      "Epoch 6/70\n",
      " - 2s - loss: 0.4748 - acc: 0.7765 - val_loss: 0.4509 - val_acc: 0.7908\n",
      "Epoch 7/70\n",
      " - 2s - loss: 0.4738 - acc: 0.7749 - val_loss: 0.4524 - val_acc: 0.7909\n",
      "Epoch 8/70\n",
      " - 2s - loss: 0.4713 - acc: 0.7768 - val_loss: 0.4469 - val_acc: 0.7916\n",
      "Epoch 9/70\n",
      " - 3s - loss: 0.4703 - acc: 0.7782 - val_loss: 0.4481 - val_acc: 0.7909\n",
      "Epoch 10/70\n",
      " - 2s - loss: 0.4689 - acc: 0.7773 - val_loss: 0.4440 - val_acc: 0.7933\n",
      "Epoch 11/70\n",
      " - 2s - loss: 0.4687 - acc: 0.7772 - val_loss: 0.4465 - val_acc: 0.7930\n",
      "Epoch 12/70\n",
      " - 2s - loss: 0.4678 - acc: 0.7760 - val_loss: 0.4465 - val_acc: 0.7939\n",
      "Epoch 13/70\n",
      " - 2s - loss: 0.4675 - acc: 0.7782 - val_loss: 0.4465 - val_acc: 0.7915\n",
      "Epoch 14/70\n",
      " - 2s - loss: 0.4651 - acc: 0.7809 - val_loss: 0.4450 - val_acc: 0.7939\n",
      "Epoch 15/70\n",
      " - 3s - loss: 0.4648 - acc: 0.7788 - val_loss: 0.4442 - val_acc: 0.7924\n",
      "Epoch 16/70\n",
      " - 2s - loss: 0.4646 - acc: 0.7813 - val_loss: 0.4491 - val_acc: 0.7934\n",
      "Epoch 17/70\n",
      " - 2s - loss: 0.4650 - acc: 0.7801 - val_loss: 0.4415 - val_acc: 0.7947\n",
      "Epoch 18/70\n",
      " - 2s - loss: 0.4665 - acc: 0.7797 - val_loss: 0.4444 - val_acc: 0.7949\n",
      "Epoch 19/70\n",
      " - 2s - loss: 0.4645 - acc: 0.7804 - val_loss: 0.4422 - val_acc: 0.7957\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.4636 - acc: 0.7789 - val_loss: 0.4430 - val_acc: 0.7954\n",
      "Epoch 21/70\n",
      " - 3s - loss: 0.4637 - acc: 0.7781 - val_loss: 0.4413 - val_acc: 0.7959\n",
      "Epoch 22/70\n",
      " - 2s - loss: 0.4608 - acc: 0.7808 - val_loss: 0.4430 - val_acc: 0.7964\n",
      "Epoch 23/70\n",
      " - 2s - loss: 0.4619 - acc: 0.7822 - val_loss: 0.4401 - val_acc: 0.7964\n",
      "Epoch 24/70\n",
      " - 2s - loss: 0.4609 - acc: 0.7814 - val_loss: 0.4403 - val_acc: 0.7962\n",
      "Epoch 25/70\n",
      " - 3s - loss: 0.4599 - acc: 0.7819 - val_loss: 0.4398 - val_acc: 0.7972\n",
      "Epoch 26/70\n",
      " - 3s - loss: 0.4616 - acc: 0.7811 - val_loss: 0.4398 - val_acc: 0.7982\n",
      "Epoch 27/70\n",
      " - 3s - loss: 0.4609 - acc: 0.7808 - val_loss: 0.4384 - val_acc: 0.7974\n",
      "Epoch 28/70\n",
      " - 3s - loss: 0.4605 - acc: 0.7821 - val_loss: 0.4426 - val_acc: 0.7965\n",
      "Epoch 29/70\n",
      " - 3s - loss: 0.4593 - acc: 0.7826 - val_loss: 0.4402 - val_acc: 0.7977\n",
      "Epoch 30/70\n",
      " - 3s - loss: 0.4582 - acc: 0.7848 - val_loss: 0.4390 - val_acc: 0.7980\n",
      "Epoch 31/70\n",
      " - 2s - loss: 0.4603 - acc: 0.7809 - val_loss: 0.4388 - val_acc: 0.7987\n",
      "Epoch 32/70\n",
      " - 2s - loss: 0.4597 - acc: 0.7814 - val_loss: 0.4414 - val_acc: 0.7976\n",
      "Epoch 33/70\n",
      " - 2s - loss: 0.4586 - acc: 0.7845 - val_loss: 0.4375 - val_acc: 0.7980\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.4572 - acc: 0.7843 - val_loss: 0.4369 - val_acc: 0.7985\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.4587 - acc: 0.7852 - val_loss: 0.4412 - val_acc: 0.7995\n",
      "Epoch 36/70\n",
      " - 2s - loss: 0.4576 - acc: 0.7842 - val_loss: 0.4419 - val_acc: 0.7991\n",
      "Epoch 37/70\n",
      " - 3s - loss: 0.4562 - acc: 0.7839 - val_loss: 0.4365 - val_acc: 0.8006\n",
      "Epoch 38/70\n",
      " - 3s - loss: 0.4565 - acc: 0.7854 - val_loss: 0.4374 - val_acc: 0.7997\n",
      "Epoch 39/70\n",
      " - 3s - loss: 0.4555 - acc: 0.7830 - val_loss: 0.4400 - val_acc: 0.8009\n",
      "Epoch 40/70\n",
      " - 3s - loss: 0.4561 - acc: 0.7840 - val_loss: 0.4347 - val_acc: 0.8009\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.4570 - acc: 0.7842 - val_loss: 0.4355 - val_acc: 0.8002\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.4538 - acc: 0.7873 - val_loss: 0.4363 - val_acc: 0.7980\n",
      "Epoch 43/70\n",
      " - 3s - loss: 0.4540 - acc: 0.7864 - val_loss: 0.4351 - val_acc: 0.8013\n",
      "Epoch 44/70\n",
      " - 2s - loss: 0.4539 - acc: 0.7860 - val_loss: 0.4386 - val_acc: 0.8005\n",
      "Epoch 45/70\n",
      " - 2s - loss: 0.4537 - acc: 0.7865 - val_loss: 0.4355 - val_acc: 0.8003\n",
      "Epoch 46/70\n",
      " - 3s - loss: 0.4534 - acc: 0.7866 - val_loss: 0.4382 - val_acc: 0.8018\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.4520 - acc: 0.7881 - val_loss: 0.4345 - val_acc: 0.8022\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.4539 - acc: 0.7852 - val_loss: 0.4369 - val_acc: 0.8017\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.4519 - acc: 0.7862 - val_loss: 0.4342 - val_acc: 0.7999\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.4520 - acc: 0.7867 - val_loss: 0.4326 - val_acc: 0.8031\n",
      "Epoch 51/70\n",
      " - 2s - loss: 0.4513 - acc: 0.7880 - val_loss: 0.4334 - val_acc: 0.8034\n",
      "Epoch 52/70\n",
      " - 2s - loss: 0.4524 - acc: 0.7856 - val_loss: 0.4332 - val_acc: 0.8003\n",
      "Epoch 53/70\n",
      " - 2s - loss: 0.4512 - acc: 0.7882 - val_loss: 0.4335 - val_acc: 0.8045\n",
      "Epoch 54/70\n",
      " - 2s - loss: 0.4523 - acc: 0.7868 - val_loss: 0.4359 - val_acc: 0.8000\n",
      "Epoch 55/70\n",
      " - 3s - loss: 0.4504 - acc: 0.7881 - val_loss: 0.4327 - val_acc: 0.8025\n",
      "Epoch 56/70\n",
      " - 3s - loss: 0.4498 - acc: 0.7879 - val_loss: 0.4320 - val_acc: 0.8028\n",
      "Epoch 57/70\n",
      " - 2s - loss: 0.4503 - acc: 0.7879 - val_loss: 0.4313 - val_acc: 0.8029\n",
      "Epoch 58/70\n",
      " - 3s - loss: 0.4492 - acc: 0.7894 - val_loss: 0.4316 - val_acc: 0.8030\n",
      "Epoch 59/70\n",
      " - 3s - loss: 0.4485 - acc: 0.7888 - val_loss: 0.4333 - val_acc: 0.8036\n",
      "Epoch 60/70\n",
      " - 2s - loss: 0.4493 - acc: 0.7889 - val_loss: 0.4309 - val_acc: 0.8028\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.4486 - acc: 0.7892 - val_loss: 0.4320 - val_acc: 0.8015\n",
      "Epoch 62/70\n",
      " - 2s - loss: 0.4472 - acc: 0.7880 - val_loss: 0.4328 - val_acc: 0.8036\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.4499 - acc: 0.7890 - val_loss: 0.4306 - val_acc: 0.8033\n",
      "Epoch 64/70\n",
      " - 2s - loss: 0.4471 - acc: 0.7893 - val_loss: 0.4300 - val_acc: 0.8053\n",
      "Epoch 65/70\n",
      " - 2s - loss: 0.4479 - acc: 0.7895 - val_loss: 0.4304 - val_acc: 0.8036\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.4483 - acc: 0.7898 - val_loss: 0.4333 - val_acc: 0.8036\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.4464 - acc: 0.7895 - val_loss: 0.4281 - val_acc: 0.8036\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.4470 - acc: 0.7900 - val_loss: 0.4246 - val_acc: 0.8058\n",
      "Epoch 69/70\n",
      " - 2s - loss: 0.4471 - acc: 0.7900 - val_loss: 0.4322 - val_acc: 0.8045\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.4455 - acc: 0.7902 - val_loss: 0.4269 - val_acc: 0.8023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4bb9105650>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=70, verbose=2, shuffle=True, validation_data = (X_test, Y_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jet_selection.h5']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.save') \n",
    "joblib.dump(model, 'jet_selection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 83.58\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_test)\n",
    "Y_valid = np.array(Y_test)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_test, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
