{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names, start = 0, stop = 20000)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for i in range(len(dftree['addbjet1_pt'])):\n",
    "#     k = np.sqrt((dftree['addbjet1_e'][i] + dftree['addbjet2_e'][i])**2 - (dftree['addbjet1_pt'][i] + dftree['addbjet2_pt'][i])**2 - (dftree['addbjet1_eta'][i] + dftree['addbjet2_eta'][i])**2 - (dftree['addbjet1_phi'][i] + dftree['addbjet2_phi'][i])**2)\n",
    "#     results.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_phi','lepton_E','MET','MET_phi','channel','event_weight']\n",
    "    \n",
    "    for t in range(1,7):\n",
    "        for i in ['jet_pT','jet_eta','jet_phi','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "            \n",
    "    end = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6:\n",
    "            parts = []\n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_phi','lepton_E','MET','MET_phi','channel']:\n",
    "                parts.append(df[t][i])\n",
    "            \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            \n",
    "            parts.append(product)\n",
    "            \n",
    "            for t in range(len(df['jet_pT'][i])):\n",
    "                passed = True\n",
    "                partial = []\n",
    "                for k in ['jet_pT','jet_eta','jet_phi','jet_E','jet_CvsB']:\n",
    "                    if k == 'jet_pT':\n",
    "                        if df[k][i][t] < 30:\n",
    "                            passed = False\n",
    "                            break\n",
    "                    elif k == 'jet_eta':\n",
    "                        if df[k][i][t] > 2.4 or df[k][i][t] < -2.4:\n",
    "                            passed = False\n",
    "                            break\n",
    "                    partial.append(df[k][i][t])\n",
    "                \n",
    "                if passed:\n",
    "                    parts += partial\n",
    "                    \n",
    "                if len(parts) == len(columns):\n",
    "                    break\n",
    "                    \n",
    "            end.append(parts)\n",
    "            \n",
    "    train_tree = pd.DataFrame(end, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree = process(dftree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree_2 = process(dftree_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree['result'] = np.zeros(len(train_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree_2['result'] = [1 for i in range(len(train_tree_2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = train_tree.append(train_tree_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = train['result']\n",
    "train = train.drop('result',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train, scaler = preprocess_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train, y_pred, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(50))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(25))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_valid_nn = np_utils.to_categorical(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12003 samples, validate on 3001 samples\n",
      "Epoch 1/40\n",
      " - 1s - loss: 0.6954 - acc: 0.5021 - val_loss: 0.6918 - val_acc: 0.5312\n",
      "Epoch 2/40\n",
      " - 0s - loss: 0.6932 - acc: 0.5098 - val_loss: 0.6914 - val_acc: 0.5288\n",
      "Epoch 3/40\n",
      " - 0s - loss: 0.6926 - acc: 0.5152 - val_loss: 0.6912 - val_acc: 0.5292\n",
      "Epoch 4/40\n",
      " - 0s - loss: 0.6927 - acc: 0.5153 - val_loss: 0.6910 - val_acc: 0.5335\n",
      "Epoch 5/40\n",
      " - 0s - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6909 - val_acc: 0.5302\n",
      "Epoch 6/40\n",
      " - 0s - loss: 0.6919 - acc: 0.5174 - val_loss: 0.6907 - val_acc: 0.5328\n",
      "Epoch 7/40\n",
      " - 1s - loss: 0.6919 - acc: 0.5171 - val_loss: 0.6905 - val_acc: 0.5348\n",
      "Epoch 8/40\n",
      " - 0s - loss: 0.6917 - acc: 0.5171 - val_loss: 0.6904 - val_acc: 0.5365\n",
      "Epoch 9/40\n",
      " - 0s - loss: 0.6912 - acc: 0.5250 - val_loss: 0.6903 - val_acc: 0.5418\n",
      "Epoch 10/40\n",
      " - 0s - loss: 0.6912 - acc: 0.5167 - val_loss: 0.6901 - val_acc: 0.5408\n",
      "Epoch 11/40\n",
      " - 0s - loss: 0.6909 - acc: 0.5274 - val_loss: 0.6900 - val_acc: 0.5415\n",
      "Epoch 12/40\n",
      " - 0s - loss: 0.6903 - acc: 0.5260 - val_loss: 0.6899 - val_acc: 0.5428\n",
      "Epoch 13/40\n",
      " - 0s - loss: 0.6901 - acc: 0.5317 - val_loss: 0.6897 - val_acc: 0.5445\n",
      "Epoch 14/40\n",
      " - 0s - loss: 0.6897 - acc: 0.5310 - val_loss: 0.6896 - val_acc: 0.5412\n",
      "Epoch 15/40\n",
      " - 0s - loss: 0.6890 - acc: 0.5381 - val_loss: 0.6894 - val_acc: 0.5468\n",
      "Epoch 16/40\n",
      " - 0s - loss: 0.6901 - acc: 0.5281 - val_loss: 0.6892 - val_acc: 0.5448\n",
      "Epoch 17/40\n",
      " - 0s - loss: 0.6895 - acc: 0.5336 - val_loss: 0.6891 - val_acc: 0.5418\n",
      "Epoch 18/40\n",
      " - 0s - loss: 0.6885 - acc: 0.5345 - val_loss: 0.6890 - val_acc: 0.5418\n",
      "Epoch 19/40\n",
      " - 1s - loss: 0.6896 - acc: 0.5305 - val_loss: 0.6887 - val_acc: 0.5455\n",
      "Epoch 20/40\n",
      " - 0s - loss: 0.6892 - acc: 0.5294 - val_loss: 0.6886 - val_acc: 0.5442\n",
      "Epoch 21/40\n",
      " - 1s - loss: 0.6888 - acc: 0.5320 - val_loss: 0.6884 - val_acc: 0.5485\n",
      "Epoch 22/40\n",
      " - 0s - loss: 0.6888 - acc: 0.5346 - val_loss: 0.6882 - val_acc: 0.5455\n",
      "Epoch 23/40\n",
      " - 0s - loss: 0.6876 - acc: 0.5388 - val_loss: 0.6880 - val_acc: 0.5488\n",
      "Epoch 24/40\n",
      " - 0s - loss: 0.6881 - acc: 0.5405 - val_loss: 0.6878 - val_acc: 0.5465\n",
      "Epoch 25/40\n",
      " - 0s - loss: 0.6872 - acc: 0.5454 - val_loss: 0.6875 - val_acc: 0.5448\n",
      "Epoch 26/40\n",
      " - 1s - loss: 0.6872 - acc: 0.5417 - val_loss: 0.6874 - val_acc: 0.5492\n",
      "Epoch 27/40\n",
      " - 1s - loss: 0.6875 - acc: 0.5390 - val_loss: 0.6871 - val_acc: 0.5472\n",
      "Epoch 28/40\n",
      " - 1s - loss: 0.6874 - acc: 0.5367 - val_loss: 0.6869 - val_acc: 0.5478\n",
      "Epoch 29/40\n",
      " - 0s - loss: 0.6868 - acc: 0.5437 - val_loss: 0.6868 - val_acc: 0.5468\n",
      "Epoch 30/40\n",
      " - 1s - loss: 0.6868 - acc: 0.5469 - val_loss: 0.6866 - val_acc: 0.5465\n",
      "Epoch 31/40\n",
      " - 0s - loss: 0.6870 - acc: 0.5418 - val_loss: 0.6865 - val_acc: 0.5475\n",
      "Epoch 32/40\n",
      " - 0s - loss: 0.6855 - acc: 0.5484 - val_loss: 0.6863 - val_acc: 0.5505\n",
      "Epoch 33/40\n",
      " - 0s - loss: 0.6857 - acc: 0.5436 - val_loss: 0.6861 - val_acc: 0.5531\n",
      "Epoch 34/40\n",
      " - 0s - loss: 0.6860 - acc: 0.5452 - val_loss: 0.6860 - val_acc: 0.5488\n",
      "Epoch 35/40\n",
      " - 0s - loss: 0.6846 - acc: 0.5468 - val_loss: 0.6857 - val_acc: 0.5501\n",
      "Epoch 36/40\n",
      " - 0s - loss: 0.6855 - acc: 0.5535 - val_loss: 0.6856 - val_acc: 0.5501\n",
      "Epoch 37/40\n",
      " - 1s - loss: 0.6853 - acc: 0.5464 - val_loss: 0.6853 - val_acc: 0.5528\n",
      "Epoch 38/40\n",
      " - 0s - loss: 0.6841 - acc: 0.5505 - val_loss: 0.6851 - val_acc: 0.5495\n",
      "Epoch 39/40\n",
      " - 0s - loss: 0.6848 - acc: 0.5543 - val_loss: 0.6849 - val_acc: 0.5462\n",
      "Epoch 40/40\n",
      " - 0s - loss: 0.6835 - acc: 0.5519 - val_loss: 0.6846 - val_acc: 0.5475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f324eaba650>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-18 18:10:00.964580: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=40, verbose=2, shuffle=True, validation_data = (X_valid, Y_valid_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_valid = np.array(Y_valid)\n",
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth':5,\n",
    "    'gamma': 0.3,\n",
    "    'min_child_weight':1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_estimators': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs = GridSearchCV(xgb, param_grid=params, cv=2, n_jobs=4, verbose=2)\n",
    "grs.fit(X_train, Y_train, eval_set=[(X_valid, Y_valid)], verbose=False)\n",
    "\n",
    "print(\"Best parameters \" + str(grs.best_params_))\n",
    "gpd = pd.DataFrame(grs.cv_results_)\n",
    "print(\"Estimated accuracy of this model for unseen data: {0:1.4f}\".format(gpd['mean_test_score'][grs.best_index_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(\n",
    "    objective = 'binary:logistic',\n",
    "    learning_rate = 0.1,\n",
    "    max_depth = 5,\n",
    "    gamma = 0,\n",
    "    min_child_weight = 1,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 0.8,\n",
    "    n_estimators = 1000,\n",
    "    silent = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=1,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(X_train, Y_train, eval_set=[(X_valid, Y_valid)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = my_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid = np.array(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gradient Boosting: 59.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Gradient Boosting: %.2f\" % (accuracy_score(Y_valid, a.round()) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 59.78\n"
     ]
    }
   ],
   "source": [
    "r = rf.predict(X_valid)\n",
    "Y_valid = np.array(Y_valid)\n",
    "print(\"Accuracy for Random Forest: %.2f\" % (accuracy_score(Y_valid, r.round()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
