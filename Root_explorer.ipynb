{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import *\n",
    "from root_numpy import tree2array\n",
    "from ROOT import TFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish.io as io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TFile.Open(\"/home/minerva1993/public/v808/nosplit/ttHbb_PowhegPythia.root\")\n",
    "data2 = TFile.Open(\"/home/minerva1993/public/v808/nosplit/TTLJ_PowhegPythia_ttbb.root\")\n",
    "tree = data.Get(\"ttbbLepJets/tree\")\n",
    "tree2 = data2.Get(\"ttbbLepJets/tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_df(tree, branch_names=[], index_name='', drop_roofit_labels=False):\n",
    "    if tree is None:\n",
    "        return None\n",
    "\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    all_branch_names = [branch_list.At(i).GetName() for i in range(branch_list.GetEntries())]\n",
    "    if len(branch_names) == 0:\n",
    "        branch_names = all_branch_names\n",
    "    for bn in branch_names[:]:\n",
    "        if bn not in all_branch_names:\n",
    "            branch_names.remove(bn)\n",
    "        if drop_roofit_labels:\n",
    "            if bn.endswith('_lbl'):\n",
    "                branch_names.remove(bn)\n",
    "\n",
    "    arrs = tree2array(tree, branch_names, start = 0, stop = 20000)\n",
    "    df = pd.DataFrame(arrs)\n",
    "\n",
    "    if len(index_name) == 0:\n",
    "        for col in df.columns:\n",
    "            if col.startswith('__index__'):\n",
    "                index_name = col\n",
    "                break\n",
    "    if len(index_name):\n",
    "        try:\n",
    "            df[index_name] = df[index_name].astype(np.int32)\n",
    "            df.set_index(index_name, inplace=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "    if drop_roofit_labels:\n",
    "        df.columns = [col.replace('_idx', '') for col in df.columns]\n",
    "\n",
    "    n_tree = tree.GetEntries()\n",
    "    n_df = len(df.index)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftree = tree_to_df(tree)\n",
    "dftree_bg = tree_to_df(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for i in range(len(dftree['addbjet1_pt'])):\n",
    "#     k = np.sqrt((dftree['addbjet1_e'][i] + dftree['addbjet2_e'][i])**2 - (dftree['addbjet1_pt'][i] + dftree['addbjet2_pt'][i])**2 - (dftree['addbjet1_eta'][i] + dftree['addbjet2_eta'][i])**2 - (dftree['addbjet1_phi'][i] + dftree['addbjet2_phi'][i])**2)\n",
    "#     results.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    columns = ['draddjets','lepton_pT','lepton_eta','lepton_phi','lepton_E','MET','MET_phi','channel','event_weight']\n",
    "    \n",
    "    for t in range(1,7):\n",
    "        for i in ['jet_pT','jet_eta','jet_phi','jet_E','jet_CvsB']:\n",
    "            columns.append(i+'_'+str(t))\n",
    "            \n",
    "    end = []\n",
    "    \n",
    "    for i in range(len(df['lepton_SF'])):\n",
    "        if df['jet_number'][i] >= 6:\n",
    "            parts = []\n",
    "            for t in ['draddjets','lepton_pT','lepton_eta','lepton_phi','lepton_E','MET','MET_phi','channel']:\n",
    "                parts.append(df[t][i])\n",
    "            \n",
    "            product = df['lepton_SF'][i][0] * df['jet_SF_CSV_30'][i][0] * df['PUWeight'][i][0] * df['genweight'][i]\n",
    "            \n",
    "            parts.append(product)\n",
    "            \n",
    "            for t in range(len(df['jet_pT'][i])):\n",
    "                passed = True\n",
    "                partial = []\n",
    "                for k in ['jet_pT','jet_eta','jet_phi','jet_E','jet_CvsB']:\n",
    "                    if k == 'jet_pT':\n",
    "                        if df[k][i][t] < 30:\n",
    "                            passed = False\n",
    "                            break\n",
    "                    elif k == 'jet_eta':\n",
    "                        if df[k][i][t] > 2.4 or df[k][i][t] < -2.4:\n",
    "                            passed = False\n",
    "                            break\n",
    "                    partial.append(df[k][i][t])\n",
    "                \n",
    "                if passed:\n",
    "                    parts += partial\n",
    "                    \n",
    "                if len(parts) == len(columns):\n",
    "                    break\n",
    "                    \n",
    "            end.append(parts)\n",
    "            \n",
    "    train_tree = pd.DataFrame(end, columns=columns)\n",
    "    return train_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree = process(dftree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree_2 = process(dftree_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree['result'] = np.zeros(len(train_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree_2['result'] = [1 for i in range(len(train_tree_2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = train_tree.append(train_tree_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = train['result']\n",
    "train = train.drop('result',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9304220184/python27/lib/python2.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train, scaler = preprocess_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train, y_pred, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.13, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(50))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(25))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_nn = np_utils.to_categorical(Y_train)\n",
    "Y_valid_nn = np_utils.to_categorical(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12003 samples, validate on 3001 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 0.7082 - acc: 0.5085 - val_loss: 0.6942 - val_acc: 0.5308\n",
      "Epoch 2/40\n",
      " - 1s - loss: 0.6992 - acc: 0.5095 - val_loss: 0.6924 - val_acc: 0.5292\n",
      "Epoch 3/40\n",
      " - 0s - loss: 0.6955 - acc: 0.5110 - val_loss: 0.6916 - val_acc: 0.5298\n",
      "Epoch 4/40\n",
      " - 0s - loss: 0.6930 - acc: 0.5221 - val_loss: 0.6912 - val_acc: 0.5278\n",
      "Epoch 5/40\n",
      " - 1s - loss: 0.6930 - acc: 0.5205 - val_loss: 0.6909 - val_acc: 0.5278\n",
      "Epoch 6/40\n",
      " - 0s - loss: 0.6916 - acc: 0.5149 - val_loss: 0.6908 - val_acc: 0.5275\n",
      "Epoch 7/40\n",
      " - 0s - loss: 0.6928 - acc: 0.5190 - val_loss: 0.6907 - val_acc: 0.5285\n",
      "Epoch 8/40\n",
      " - 0s - loss: 0.6915 - acc: 0.5204 - val_loss: 0.6904 - val_acc: 0.5308\n",
      "Epoch 9/40\n",
      " - 0s - loss: 0.6924 - acc: 0.5165 - val_loss: 0.6904 - val_acc: 0.5298\n",
      "Epoch 10/40\n",
      " - 0s - loss: 0.6903 - acc: 0.5215 - val_loss: 0.6902 - val_acc: 0.5345\n",
      "Epoch 11/40\n",
      " - 0s - loss: 0.6899 - acc: 0.5286 - val_loss: 0.6901 - val_acc: 0.5335\n",
      "Epoch 12/40\n",
      " - 0s - loss: 0.6903 - acc: 0.5314 - val_loss: 0.6900 - val_acc: 0.5275\n",
      "Epoch 13/40\n",
      " - 1s - loss: 0.6912 - acc: 0.5260 - val_loss: 0.6899 - val_acc: 0.5302\n",
      "Epoch 14/40\n",
      " - 1s - loss: 0.6897 - acc: 0.5225 - val_loss: 0.6898 - val_acc: 0.5288\n",
      "Epoch 15/40\n",
      " - 1s - loss: 0.6890 - acc: 0.5271 - val_loss: 0.6897 - val_acc: 0.5325\n",
      "Epoch 16/40\n",
      " - 1s - loss: 0.6888 - acc: 0.5320 - val_loss: 0.6897 - val_acc: 0.5362\n",
      "Epoch 17/40\n",
      " - 1s - loss: 0.6883 - acc: 0.5355 - val_loss: 0.6895 - val_acc: 0.5358\n",
      "Epoch 18/40\n",
      " - 1s - loss: 0.6892 - acc: 0.5322 - val_loss: 0.6894 - val_acc: 0.5408\n",
      "Epoch 19/40\n",
      " - 0s - loss: 0.6885 - acc: 0.5393 - val_loss: 0.6891 - val_acc: 0.5388\n",
      "Epoch 20/40\n",
      " - 1s - loss: 0.6883 - acc: 0.5369 - val_loss: 0.6891 - val_acc: 0.5402\n",
      "Epoch 21/40\n",
      " - 0s - loss: 0.6892 - acc: 0.5331 - val_loss: 0.6892 - val_acc: 0.5422\n",
      "Epoch 22/40\n",
      " - 0s - loss: 0.6880 - acc: 0.5366 - val_loss: 0.6889 - val_acc: 0.5375\n",
      "Epoch 23/40\n",
      " - 0s - loss: 0.6876 - acc: 0.5385 - val_loss: 0.6888 - val_acc: 0.5395\n",
      "Epoch 24/40\n",
      " - 0s - loss: 0.6862 - acc: 0.5427 - val_loss: 0.6888 - val_acc: 0.5422\n",
      "Epoch 25/40\n",
      " - 1s - loss: 0.6865 - acc: 0.5473 - val_loss: 0.6886 - val_acc: 0.5425\n",
      "Epoch 26/40\n",
      " - 0s - loss: 0.6871 - acc: 0.5455 - val_loss: 0.6885 - val_acc: 0.5478\n",
      "Epoch 27/40\n",
      " - 0s - loss: 0.6869 - acc: 0.5414 - val_loss: 0.6882 - val_acc: 0.5412\n",
      "Epoch 28/40\n",
      " - 1s - loss: 0.6870 - acc: 0.5423 - val_loss: 0.6881 - val_acc: 0.5415\n",
      "Epoch 29/40\n",
      " - 1s - loss: 0.6885 - acc: 0.5329 - val_loss: 0.6882 - val_acc: 0.5478\n",
      "Epoch 30/40\n",
      " - 1s - loss: 0.6863 - acc: 0.5391 - val_loss: 0.6880 - val_acc: 0.5492\n",
      "Epoch 31/40\n",
      " - 1s - loss: 0.6842 - acc: 0.5462 - val_loss: 0.6877 - val_acc: 0.5468\n",
      "Epoch 32/40\n",
      " - 0s - loss: 0.6853 - acc: 0.5461 - val_loss: 0.6877 - val_acc: 0.5521\n",
      "Epoch 33/40\n",
      " - 1s - loss: 0.6839 - acc: 0.5474 - val_loss: 0.6875 - val_acc: 0.5525\n",
      "Epoch 34/40\n",
      " - 1s - loss: 0.6842 - acc: 0.5519 - val_loss: 0.6872 - val_acc: 0.5558\n",
      "Epoch 35/40\n",
      " - 1s - loss: 0.6846 - acc: 0.5458 - val_loss: 0.6871 - val_acc: 0.5538\n",
      "Epoch 36/40\n",
      " - 1s - loss: 0.6853 - acc: 0.5444 - val_loss: 0.6871 - val_acc: 0.5538\n",
      "Epoch 37/40\n",
      " - 1s - loss: 0.6844 - acc: 0.5500 - val_loss: 0.6871 - val_acc: 0.5505\n",
      "Epoch 38/40\n",
      " - 1s - loss: 0.6850 - acc: 0.5466 - val_loss: 0.6868 - val_acc: 0.5511\n",
      "Epoch 39/40\n",
      " - 1s - loss: 0.6849 - acc: 0.5445 - val_loss: 0.6868 - val_acc: 0.5541\n",
      "Epoch 40/40\n",
      " - 1s - loss: 0.6840 - acc: 0.5490 - val_loss: 0.6865 - val_acc: 0.5535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66b4de7310>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-17 17:57:33.356699: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_nn, batch_size=64, epochs=40, verbose=2, shuffle=True, validation_data = (X_valid, Y_valid_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
